{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b31955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'Normal Videos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318577 images belonging to 14 classes.\n",
      "Found 46356 images belonging to 14 classes.\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\AppData\\Local\\Temp\\ipykernel_20748\\3125170655.py:138: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/3500 [==============================] - ETA: 0s - loss: 1.7598 - accuracy: 0.4801\n",
      "Epoch 1: accuracy improved from -inf to 0.48008, saving model to weights-improvement-01-0.48.hdf5\n",
      "3500/3500 [==============================] - 1176s 336ms/step - loss: 1.7598 - accuracy: 0.4801 - val_loss: 5.4282 - val_accuracy: 0.0723\n",
      "Epoch 2/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 1.1754 - accuracy: 0.6847\n",
      "Epoch 2: accuracy improved from 0.48008 to 0.68472, saving model to weights-improvement-02-0.68.hdf5\n",
      "3500/3500 [==============================] - 1356s 387ms/step - loss: 1.1754 - accuracy: 0.6847 - val_loss: 4.3931 - val_accuracy: 0.0734\n",
      "Epoch 3/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.8841 - accuracy: 0.7822\n",
      "Epoch 3: accuracy improved from 0.68472 to 0.78220, saving model to weights-improvement-03-0.78.hdf5\n",
      "3500/3500 [==============================] - 1077s 308ms/step - loss: 0.8841 - accuracy: 0.7822 - val_loss: 3.9694 - val_accuracy: 0.0830\n",
      "Epoch 4/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.7065 - accuracy: 0.8400\n",
      "Epoch 4: accuracy improved from 0.78220 to 0.83996, saving model to weights-improvement-04-0.84.hdf5\n",
      "3500/3500 [==============================] - 901s 257ms/step - loss: 0.7065 - accuracy: 0.8400 - val_loss: 4.6369 - val_accuracy: 0.1350\n",
      "Epoch 5/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.8754\n",
      "Epoch 5: accuracy improved from 0.83996 to 0.87541, saving model to weights-improvement-05-0.88.hdf5\n",
      "3500/3500 [==============================] - 820s 234ms/step - loss: 0.5883 - accuracy: 0.8754 - val_loss: 4.4681 - val_accuracy: 0.1134\n",
      "Epoch 6/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.9001\n",
      "Epoch 6: accuracy improved from 0.87541 to 0.90014, saving model to weights-improvement-06-0.90.hdf5\n",
      "3500/3500 [==============================] - 755s 216ms/step - loss: 0.5061 - accuracy: 0.9001 - val_loss: 4.8251 - val_accuracy: 0.1191\n",
      "Epoch 7/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.9183\n",
      "Epoch 7: accuracy improved from 0.90014 to 0.91827, saving model to weights-improvement-07-0.92.hdf5\n",
      "3500/3500 [==============================] - 666s 190ms/step - loss: 0.4511 - accuracy: 0.9183 - val_loss: 4.5299 - val_accuracy: 0.1069\n",
      "Epoch 8/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.4031 - accuracy: 0.9307\n",
      "Epoch 8: accuracy improved from 0.91827 to 0.93066, saving model to weights-improvement-08-0.93.hdf5\n",
      "3500/3500 [==============================] - 648s 185ms/step - loss: 0.4031 - accuracy: 0.9307 - val_loss: 5.0513 - val_accuracy: 0.1024\n",
      "Epoch 9/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.9373\n",
      "Epoch 9: accuracy improved from 0.93066 to 0.93730, saving model to weights-improvement-09-0.94.hdf5\n",
      "3500/3500 [==============================] - 589s 168ms/step - loss: 0.3812 - accuracy: 0.9373 - val_loss: 5.8196 - val_accuracy: 0.0933\n",
      "Epoch 10/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.9458\n",
      "Epoch 10: accuracy improved from 0.93730 to 0.94584, saving model to weights-improvement-10-0.95.hdf5\n",
      "3500/3500 [==============================] - 647s 185ms/step - loss: 0.3507 - accuracy: 0.9458 - val_loss: 4.3598 - val_accuracy: 0.1454\n",
      "Epoch 11/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.9485\n",
      "Epoch 11: accuracy improved from 0.94584 to 0.94845, saving model to weights-improvement-11-0.95.hdf5\n",
      "3500/3500 [==============================] - 565s 162ms/step - loss: 0.3378 - accuracy: 0.9485 - val_loss: 4.9667 - val_accuracy: 0.1207\n",
      "Epoch 12/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.3179 - accuracy: 0.9548\n",
      "Epoch 12: accuracy improved from 0.94845 to 0.95484, saving model to weights-improvement-12-0.95.hdf5\n",
      "3500/3500 [==============================] - 552s 158ms/step - loss: 0.3179 - accuracy: 0.9548 - val_loss: 4.8310 - val_accuracy: 0.1275\n",
      "Epoch 13/15\n",
      "3499/3500 [============================>.] - ETA: 0s - loss: 0.3021 - accuracy: 0.9603\n",
      "Epoch 13: accuracy improved from 0.95484 to 0.96036, saving model to weights-improvement-13-0.96.hdf5\n",
      "3500/3500 [==============================] - 561s 160ms/step - loss: 0.3021 - accuracy: 0.9604 - val_loss: 5.3397 - val_accuracy: 0.0979\n",
      "Epoch 14/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.9625\n",
      "Epoch 14: accuracy improved from 0.96036 to 0.96248, saving model to weights-improvement-14-0.96.hdf5\n",
      "3500/3500 [==============================] - 547s 156ms/step - loss: 0.2935 - accuracy: 0.9625 - val_loss: 5.2196 - val_accuracy: 0.0993\n",
      "Epoch 15/15\n",
      "3500/3500 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.9642\n",
      "Epoch 15: accuracy improved from 0.96248 to 0.96418, saving model to weights-improvement-15-0.96.hdf5\n",
      "3500/3500 [==============================] - 435s 124ms/step - loss: 0.2864 - accuracy: 0.9642 - val_loss: 5.6508 - val_accuracy: 0.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\AppData\\Local\\Temp\\ipykernel_20748\\3125170655.py:151: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 13, does not match size of target_names, 14. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 160\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Calculate and print classification report\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Generate and print confusion matrix\u001b[39;00m\n\u001b[0;32m    163\u001b[0m conf_mat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2329\u001b[0m             )\n\u001b[0;32m   2330\u001b[0m         )\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2336\u001b[0m         )\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 13, does not match size of target_names, 14. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "num_classes = 14\n",
    "images_per_class = 4000  # Number of images per class for training\n",
    "\n",
    "train1_data = r'C:\\AHAR\\Train'\n",
    "validation1_data = r'C:\\AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'Normal Videos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 50\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [model_checkpoint]\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Define your train and validation generators with limited images per class\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    steps_per_epoch=(images_per_class * len(class_labels)) // 16,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=17000 // 64\n",
    ")\n",
    "\n",
    "model.save('model_cnn_abnormal_detection.h5')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "validation_generator.reset()  # Reset the generator to avoid data duplication\n",
    "predictions = model.predict_generator(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n",
    "y_true = validation_generator.classes\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert class indices to class labels\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Calculate and print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "# Generate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1acbc599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'Normal Videos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Found 10132 images belonging to 14 classes.\n",
      "Found 10132 images belonging to 14 classes.\n",
      "Epoch 1/10\n",
      "634/634 [==============================] - 49s 75ms/step - loss: 0.9374 - accuracy: 0.8087 - val_loss: 1.8642 - val_accuracy: 0.4099\n",
      "Epoch 2/10\n",
      "634/634 [==============================] - 48s 75ms/step - loss: 0.3077 - accuracy: 0.9697 - val_loss: 0.8003 - val_accuracy: 0.7364\n",
      "Epoch 3/10\n",
      "634/634 [==============================] - 47s 75ms/step - loss: 0.2313 - accuracy: 0.9826 - val_loss: 0.5215 - val_accuracy: 0.8880\n",
      "Epoch 4/10\n",
      "634/634 [==============================] - 47s 75ms/step - loss: 0.2081 - accuracy: 0.9834 - val_loss: 1.5695 - val_accuracy: 0.5991\n",
      "Epoch 5/10\n",
      "634/634 [==============================] - 47s 75ms/step - loss: 0.1889 - accuracy: 0.9869 - val_loss: 4.5524 - val_accuracy: 0.3898\n",
      "Epoch 6/10\n",
      "634/634 [==============================] - 47s 75ms/step - loss: 0.2005 - accuracy: 0.9812 - val_loss: 4.0346 - val_accuracy: 0.3151\n",
      "Epoch 7/10\n",
      "634/634 [==============================] - 48s 75ms/step - loss: 0.1683 - accuracy: 0.9887 - val_loss: 7.5681 - val_accuracy: 0.2478\n",
      "Epoch 8/10\n",
      "634/634 [==============================] - 48s 75ms/step - loss: 0.1590 - accuracy: 0.9917 - val_loss: 0.4461 - val_accuracy: 0.8666\n",
      "Epoch 9/10\n",
      "634/634 [==============================] - 48s 76ms/step - loss: 0.1632 - accuracy: 0.9865 - val_loss: 0.6609 - val_accuracy: 0.7802\n",
      "Epoch 10/10\n",
      "634/634 [==============================] - 48s 75ms/step - loss: 0.1475 - accuracy: 0.9919 - val_loss: 0.1263 - val_accuracy: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1292ea02530>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "train1_data = r'D:\\AHAR\\Test'\n",
    "validation1_data = r'D:\\AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Define your train and validation generators with limited images per class\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "\n",
    "# model.save('model_cnn_abnormal_detection.h5')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "# validation_generator.reset()  # Reset the generator to avoid data duplication\n",
    "# predictions = model.predict_generator(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n",
    "# y_true = validation_generator.classes\n",
    "# y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Convert class indices to class labels\n",
    "# class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# # Calculate and print classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "# # Generate and print confusion matrix\n",
    "# conf_mat = confusion_matrix(y_true, y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cfb1244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes in the Test Set: [ 0  1  2  3  4  5  6  8  9 10 11]\n",
      "159/159 [==============================] - 9s 52ms/step - loss: 0.1263 - accuracy: 0.9956\n",
      "159/159 [==============================] - 8s 51ms/step\n",
      "Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 11, does not match size of target_names, 14. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Print classification report\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Print confusion matrix\u001b[39;00m\n\u001b[0;32m     43\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(true_labels, predicted_labels)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2329\u001b[0m             )\n\u001b[0;32m   2330\u001b[0m         )\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2336\u001b[0m         )\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 11, does not match size of target_names, 14. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# #Evaluate the model on the validation set\n",
    "# test_set.reset()  # Reset the generator to avoid data duplication\n",
    "# predictions = model.predict_generator(test_set, steps=test_set.samples // test_set.batch_size + 1)\n",
    "# y_true = test_set.classes\n",
    "# y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Convert class indices to class labels\n",
    "# class_labels = list(test_set.class_indices.keys())\n",
    "\n",
    "# # Calculate and print classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "# # Generate and print confusion matrix\n",
    "# conf_mat = confusion_matrix(y_true, y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_mat)\n",
    "\n",
    "# Check unique classes in the test set\n",
    "unique_classes = np.unique(true_labels)\n",
    "print(\"Unique Classes in the Test Set:\", unique_classes)\n",
    "\n",
    "# Update class_labels with correct class labels based on your dataset\n",
    "class_labels = ['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "                'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ab09f",
   "metadata": {},
   "source": [
    "# Almost correct code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564565f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55997 images belonging to 14 classes.\n",
      "Found 11132 images belonging to 14 classes.\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1503s 429ms/step - loss: 0.9903 - accuracy: 0.7655 - val_loss: 5.9395 - val_accuracy: 0.0872\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 225s 64ms/step - loss: 0.4074 - accuracy: 0.9351 - val_loss: 7.8458 - val_accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 227s 65ms/step - loss: 0.3307 - accuracy: 0.9576 - val_loss: 8.3651 - val_accuracy: 0.0839\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 227s 65ms/step - loss: 0.3071 - accuracy: 0.9641 - val_loss: 8.2109 - val_accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 227s 65ms/step - loss: 0.2892 - accuracy: 0.9681 - val_loss: 7.7160 - val_accuracy: 0.0623\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 236s 68ms/step - loss: 0.2744 - accuracy: 0.9714 - val_loss: 10.6840 - val_accuracy: 0.0825\n",
      "Epoch 7/10\n",
      " 112/3500 [..............................] - ETA: 3:33 - loss: 0.2759 - accuracy: 0.9715"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 134\u001b[0m\n\u001b[0;32m    112\u001b[0m training_set \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m    113\u001b[0m     train1_data,\n\u001b[0;32m    114\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    124\u001b[0m test_set \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m    125\u001b[0m     validation1_data,\n\u001b[0;32m    126\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    132\u001b[0m )\n\u001b[1;32m--> 134\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1413\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1411\u001b[0m   context\u001b[38;5;241m.\u001b[39masync_wait()\n\u001b[0;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m-> 1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m \u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_increment\u001b[49m\n\u001b[0;32m   1414\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1268\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1265\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m steps_remaining\n\u001b[0;32m   1266\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39massign(original_spe)\n\u001b[1;32m-> 1268\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_increment\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1270\u001b[0m   \u001b[38;5;124;03m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_increment\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "train1_data = r'D:\\AHAR\\Train'\n",
    "validation1_data = r'D:\\AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Define your train and validation generators with limited images per class\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "\n",
    "# model.save('model_cnn_abnormal_detection.h5')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "# validation_generator.reset()  # Reset the generator to avoid data duplication\n",
    "# predictions = model.predict_generator(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n",
    "# y_true = validation_generator.classes\n",
    "# y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Convert class indices to class labels\n",
    "# class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# # Calculate and print classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "# # Generate and print confusion matrix\n",
    "# conf_mat = confusion_matrix(y_true, y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8427d2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 9s 51ms/step - loss: 9.6605 - accuracy: 0.0681\n",
      "174/174 [==============================] - 9s 50ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Abuse       0.03      0.40      0.05       297\n",
      "       Arrest       0.08      0.02      0.04      1000\n",
      "        Arson       0.09      0.12      0.10      1000\n",
      "      Assault       0.09      0.24      0.13      1000\n",
      "     Burglary       0.13      0.00      0.01      1000\n",
      "    Explosion       0.10      0.08      0.08      1000\n",
      "     Fighting       0.00      0.00      0.00      1000\n",
      " NormalVideos       0.07      0.01      0.02      1000\n",
      "RoadAccidents       0.11      0.02      0.04      1000\n",
      "      Robbery       0.11      0.02      0.03       835\n",
      "     Shooting       0.09      0.01      0.02      1000\n",
      "  Shoplifting       0.13      0.00      0.01      1000\n",
      "     Stealing       0.00      0.00      0.00         0\n",
      "    Vandalism       0.00      0.00      0.00         0\n",
      "\n",
      "     accuracy                           0.06     11132\n",
      "    macro avg       0.07      0.07      0.04     11132\n",
      " weighted avg       0.09      0.06      0.04     11132\n",
      "\n",
      "Confusion Matrix:\n",
      "[[120  11  27  72   0  21   0   1   5   5   4   1   3  27]\n",
      " [412  23 113 243   1  73   0  13  15  10   8   4   7  78]\n",
      " [372  20 115 255   7  72   0  31  21  17  11   2   8  69]\n",
      " [411  36 124 239   1  71   0   7  13  10   7   2   8  71]\n",
      " [412  26 116 218   4  70   0  17  16  14  10   2  11  84]\n",
      " [384  17 141 230   2  76   0  14  16   8   8   2  14  88]\n",
      " [379  25 140 237   2  76   0   9   9   6  13   1   9  94]\n",
      " [408  24 109 217   1  76   0  13  21  12   8   1  12  98]\n",
      " [414  27 107 221   4  72   0  18  22  13   9   1  13  79]\n",
      " [335  31  88 189   4  60   0  16  22  16   2   2   7  63]\n",
      " [370  36 117 252   1  63   0  17  18  18   9   2  11  86]\n",
      " [393  23 105 228   4  69   0  28  26  20  10   3  13  78]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13b89b",
   "metadata": {},
   "source": [
    "# CODE WITH CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c47e3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 400, 64)      0           ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " lstm1 (LSTM)                   (None, 64)           33024       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 14)           910         ['lstm1[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 266,286\n",
      "Trainable params: 265,102\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 400, 64)      0           ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " lstm1 (LSTM)                   (None, 64)           33024       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 14)           910         ['lstm1[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 266,286\n",
      "Trainable params: 265,102\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Found 55997 images belonging to 14 classes.\n",
      "Found 11132 images belonging to 14 classes.\n",
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 1719s 482ms/step - loss: 2.0371 - accuracy: 0.3723 - val_loss: 3.2053 - val_accuracy: 0.1588\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 250s 71ms/step - loss: 1.2746 - accuracy: 0.6380 - val_loss: 3.9423 - val_accuracy: 0.1298\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 241s 69ms/step - loss: 0.7936 - accuracy: 0.7923 - val_loss: 4.4700 - val_accuracy: 0.0837\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 241s 69ms/step - loss: 0.5555 - accuracy: 0.8626 - val_loss: 5.7859 - val_accuracy: 0.0552\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 253s 72ms/step - loss: 0.3999 - accuracy: 0.9070 - val_loss: 5.5337 - val_accuracy: 0.1084\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 245s 70ms/step - loss: 0.3128 - accuracy: 0.9301 - val_loss: 5.6478 - val_accuracy: 0.1176\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 244s 70ms/step - loss: 0.2563 - accuracy: 0.9445 - val_loss: 6.1306 - val_accuracy: 0.0861\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 255s 73ms/step - loss: 0.2214 - accuracy: 0.9524 - val_loss: 6.4895 - val_accuracy: 0.0903\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 247s 71ms/step - loss: 0.1954 - accuracy: 0.9577 - val_loss: 6.2177 - val_accuracy: 0.0964\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 240s 69ms/step - loss: 0.1695 - accuracy: 0.9641 - val_loss: 6.5945 - val_accuracy: 0.0840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ceada3e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "train1_data = r'D:\\AHAR\\Train'\n",
    "validation1_data = r'D:\\AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "num_classes = len(class_labels)  # Assuming class_labels is defined somewhere in your code\n",
    "LR = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "\n",
    "# Reshape the output from the last layer before passing it to LSTM\n",
    "reshaped_layer = Reshape((20 * 20, 64))(layer10)  # Adjust the shape based on your specific spatial dimensions\n",
    "\n",
    "# Add LSTM layer\n",
    "lstm_units = 64\n",
    "lstm_layer = LSTM(units=lstm_units, name='lstm1')(reshaped_layer)\n",
    "\n",
    "# Output block\n",
    "layer21 = Dense(num_classes, activation='softmax', name='dense1')(lstm_layer)\n",
    "\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input], outputs=[layer21])\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Define your train and validation generators with limited images per class\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "# validation_generator.reset()  # Reset the generator to avoid data duplication\n",
    "# predictions = model.predict_generator(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n",
    "# y_true = validation_generator.classes\n",
    "# y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Convert class indices to class labels\n",
    "# class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# # Calculate and print classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "# # Generate and print confusion matrix\n",
    "# conf_mat = confusion_matrix(y_true, y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb47d64",
   "metadata": {},
   "source": [
    "# Almost Correct Code with Canny edge detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eb80208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  4704        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,248\n",
      "Trainable params: 232,064\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Found 55997 images belonging to 14 classes.\n",
      "Found 11132 images belonging to 14 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1663: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1671: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 5302s 2s/step - loss: 1.9098 - accuracy: 0.4369 - val_loss: 27415.6875 - val_accuracy: 0.0891\n",
      "Epoch 2/10\n",
      "3500/3500 [==============================] - 478s 136ms/step - loss: 1.1140 - accuracy: 0.7180 - val_loss: 8921.0352 - val_accuracy: 0.0907\n",
      "Epoch 3/10\n",
      "3500/3500 [==============================] - 461s 132ms/step - loss: 0.8125 - accuracy: 0.8165 - val_loss: 7750.8701 - val_accuracy: 0.0792\n",
      "Epoch 4/10\n",
      "3500/3500 [==============================] - 474s 135ms/step - loss: 0.6854 - accuracy: 0.8597 - val_loss: 7211.3203 - val_accuracy: 0.0900\n",
      "Epoch 5/10\n",
      "3500/3500 [==============================] - 461s 132ms/step - loss: 0.6293 - accuracy: 0.8770 - val_loss: 7302.3442 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "3500/3500 [==============================] - 450s 129ms/step - loss: 0.5905 - accuracy: 0.8926 - val_loss: 16053.1484 - val_accuracy: 0.0898\n",
      "Epoch 7/10\n",
      "3500/3500 [==============================] - 471s 135ms/step - loss: 0.5645 - accuracy: 0.9029 - val_loss: 24147.5469 - val_accuracy: 0.0267\n",
      "Epoch 8/10\n",
      "3500/3500 [==============================] - 469s 134ms/step - loss: 0.5524 - accuracy: 0.9078 - val_loss: 11899.3730 - val_accuracy: 0.0505\n",
      "Epoch 9/10\n",
      "3500/3500 [==============================] - 473s 135ms/step - loss: 0.5425 - accuracy: 0.9118 - val_loss: 6998.8564 - val_accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "3500/3500 [==============================] - 460s 131ms/step - loss: 0.5240 - accuracy: 0.9181 - val_loss: 5989.9600 - val_accuracy: 0.0898\n",
      "174/174 [==============================] - 9s 54ms/step - loss: 5989.9624 - accuracy: 0.0898\n",
      "174/174 [==============================] - 16s 54ms/step\n",
      "Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 12, does not match size of target_names, 14. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 192\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Print classification report\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Print confusion matrix\u001b[39;00m\n\u001b[0;32m    195\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(true_labels, predicted_labels)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2329\u001b[0m             )\n\u001b[0;32m   2330\u001b[0m         )\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2336\u001b[0m         )\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 12, does not match size of target_names, 14. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img,array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\AHAR\\Train'\n",
    "validation1_data = r'D:\\AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "\n",
    "# Function to load, convert to grayscale, and apply Canny edge detection\n",
    "def load_and_apply_canny_edge(img_array, target_size=(IMG_SIZE, IMG_SIZE), canny_low_threshold=50, canny_high_threshold=150):\n",
    "    img = array_to_img(img_array)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    img_gray = img.convert('L')\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    img_canny = feature.canny(np.array(img_gray), sigma=1)\n",
    "    \n",
    "    # Convert back to 3 channels\n",
    "    img_canny = np.stack([img_canny] * 3, axis=-1)\n",
    "    \n",
    "    # Resize to target size\n",
    "    img_canny_resized = transform.resize(img_canny, target_size)\n",
    "    \n",
    "    # Convert to float32\n",
    "    img_canny_resized = img_canny_resized.astype('float32')\n",
    "    \n",
    "    return img_canny_resized\n",
    "\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    preprocessing_function=load_and_apply_canny_edge  # Apply the Canny edge detection function\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Define your train and validation generators with limited images per class\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd2a84",
   "metadata": {},
   "source": [
    "# # Almost correct code for input images as canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393f3621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_8[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,112\n",
      "Trainable params: 228,928\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_8[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,112\n",
      "Trainable params: 228,928\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Found 78049 images belonging to 14 classes.\n",
      "Found 19414 images belonging to 14 classes.\n",
      "Epoch 1/10\n",
      "4879/4879 [==============================] - ETA: 0s - loss: 2.0697 - accuracy: 0.3608"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 150\u001b[0m\n\u001b[0;32m    126\u001b[0m training_set \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m    127\u001b[0m     train1_data,\n\u001b[0;32m    128\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    137\u001b[0m )\n\u001b[0;32m    139\u001b[0m test_set \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m    140\u001b[0m     validation1_data,\n\u001b[0;32m    141\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    148\u001b[0m )\n\u001b[1;32m--> 150\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m    160\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_set, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_set))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1432\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1433\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1434\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1443\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1444\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1445\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1457\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1458\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1755\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1756\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1757\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1758\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img,array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\OUTPUT_AHAR\\Train'\n",
    "validation1_data = r'D:\\OUTPUT_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    \n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9704a6c0",
   "metadata": {},
   "source": [
    "\n",
    "# NEW CORRECT CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4fe706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_11[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,112\n",
      "Trainable params: 228,928\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_11[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,112\n",
      "Trainable params: 228,928\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78049 images belonging to 14 classes.\n",
      "Found 19414 images belonging to 14 classes.\n",
      "Epoch 1/10\n",
      "4879/4879 [==============================] - 1929s 395ms/step - loss: 2.0673 - accuracy: 0.3642 - val_loss: 3.7740 - val_accuracy: 0.1515\n",
      "Epoch 2/10\n",
      "4879/4879 [==============================] - 236s 48ms/step - loss: 1.7327 - accuracy: 0.4899 - val_loss: 2.9906 - val_accuracy: 0.1773\n",
      "Epoch 3/10\n",
      "4879/4879 [==============================] - 234s 48ms/step - loss: 1.4656 - accuracy: 0.5951 - val_loss: 3.3542 - val_accuracy: 0.2428\n",
      "Epoch 4/10\n",
      "4879/4879 [==============================] - 236s 48ms/step - loss: 1.2850 - accuracy: 0.6631 - val_loss: 4.5073 - val_accuracy: 0.1804\n",
      "Epoch 5/10\n",
      "4879/4879 [==============================] - 240s 49ms/step - loss: 1.1694 - accuracy: 0.7056 - val_loss: 3.5873 - val_accuracy: 0.2556\n",
      "Epoch 6/10\n",
      "4879/4879 [==============================] - 243s 50ms/step - loss: 1.0969 - accuracy: 0.7336 - val_loss: 3.8024 - val_accuracy: 0.2459\n",
      "Epoch 7/10\n",
      "4879/4879 [==============================] - 243s 50ms/step - loss: 1.0525 - accuracy: 0.7508 - val_loss: 4.2790 - val_accuracy: 0.2909\n",
      "Epoch 8/10\n",
      "4879/4879 [==============================] - 245s 50ms/step - loss: 1.0129 - accuracy: 0.7643 - val_loss: 5.3047 - val_accuracy: 0.2088\n",
      "Epoch 9/10\n",
      "4879/4879 [==============================] - 246s 50ms/step - loss: 0.9807 - accuracy: 0.7808 - val_loss: 4.0580 - val_accuracy: 0.2751\n",
      "Epoch 10/10\n",
      "4879/4879 [==============================] - 250s 51ms/step - loss: 0.9591 - accuracy: 0.7890 - val_loss: 4.3043 - val_accuracy: 0.2878\n",
      "304/304 [==============================] - 21s 70ms/step - loss: 4.3043 - accuracy: 0.2878\n",
      "304/304 [==============================] - 22s 71ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Abuse       0.07      0.10      0.08      1322\n",
      "       Arrest       0.11      0.03      0.05      2038\n",
      "        Arson       0.07      0.04      0.05      1474\n",
      "      Assault       0.04      0.06      0.05       922\n",
      "     Burglary       0.10      0.03      0.05      1683\n",
      "    Explosion       0.05      0.04      0.04       993\n",
      "     Fighting       0.12      0.09      0.10      2340\n",
      " NormalVideos       0.04      0.04      0.04       800\n",
      "RoadAccidents       0.09      0.18      0.12      1755\n",
      "      Robbery       0.16      0.30      0.21      3197\n",
      "     Shooting       0.03      0.05      0.03       500\n",
      "  Shoplifting       0.04      0.02      0.02       755\n",
      "     Stealing       0.11      0.01      0.02       820\n",
      "    Vandalism       0.05      0.03      0.04       815\n",
      "\n",
      "     accuracy                           0.10     19414\n",
      "    macro avg       0.08      0.07      0.07     19414\n",
      " weighted avg       0.09      0.10      0.09     19414\n",
      "\n",
      "Confusion Matrix:\n",
      "[[130  29  66  79  36  46 137  58 210 409  61  17   8  36]\n",
      " [208  65  84 125  55  71 187  93 357 611 100  22  11  49]\n",
      " [159  41  61 109  32  45 135  56 254 435  77  20   5  45]\n",
      " [ 88  29  40  51  36  26  76  33 157 307  39  11   2  27]\n",
      " [160  60  72  97  52  65 158  75 281 511  86  25   5  36]\n",
      " [103  20  45  76  25  36  90  39 157 312  47   9   5  29]\n",
      " [244  82 103 154  67  89 216  89 399 682 113  29  11  62]\n",
      " [ 69  29  27  58  26  18  79  32 131 255  41  10   4  21]\n",
      " [155  52  73 131  50  71 163  73 313 525  68  30   5  46]\n",
      " [339 117 143 179  79 105 273 115 587 955 151  58   8  88]\n",
      " [ 55  14  19  28  12  22  46  17 101 144  24   6   2  10]\n",
      " [ 67  27  34  35  25  26  78  32 136 225  28  12   3  27]\n",
      " [ 88  24  40  36  28  20  80  31 141 253  35  14   9  21]\n",
      " [ 76  30  43  61  20  28  70  37 136 233  41  15   1  24]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img,array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\OUTPUT_AHAR\\Train'\n",
    "validation1_data = r'D:\\OUTPUT_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    \n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0822c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AHAR_savedmodel_epoch10_accuracy_.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f08b7",
   "metadata": {},
   "source": [
    "# CODE TO APPLY MODEL TO VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dd9cde0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Stealing\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Stealing\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from collections import deque\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_savedmodel_epoch10_accuracy_29.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'D:\\AHAR\\Abuse\\Abuse001_x264.mp4')  # Replace 'your_video_path.mp4' with the actual path\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))  # Adjust size based on your model input size\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale if needed\n",
    "    preprocessed_frame = img_to_array(frame)\n",
    "    preprocessed_frame = preprocess_input(preprocessed_frame)\n",
    "    preprocessed_frame = np.expand_dims(preprocessed_frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(preprocessed_frame)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    predicted_label = class_labels[np.argmax(predictions)]\n",
    "\n",
    "    # Display the prediction on the frame\n",
    "#     cv2.putText(frame, f'Prediction: {predicted_label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    print(predicted_label)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7672fea7",
   "metadata": {},
   "source": [
    "# IN TERMS OF DANGER LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2b1dbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_savedmodel_epoch10_accuracy_29.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Get the number of classes in the model\n",
    "num_classes = model.output_shape[1]\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    i: i // (num_classes // 4) for i in range(num_classes)\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\Harshi\\Downloads\\production_id_4052825 (2160p).mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    predicted_label = class_mapping[np.argmax(predictions)]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {predicted_label}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#     print(predicted_label)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27465ba7",
   "metadata": {},
   "source": [
    "# ANOTHER WORKING CODE FOR DANGER LEVEL IDENTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_savedmodel_epoch10_accuracy_29.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    'Abuse': 2,          # Medium danger\n",
    "    'Arrest': 3,         # High danger\n",
    "    'Arson': 3,          # High danger\n",
    "    'Assault': 2,        # Medium danger\n",
    "    'Burglary': 3,       # High danger\n",
    "    'Explosion': 3,      # High danger\n",
    "    'Fighting': 2,       # Medium danger\n",
    "    'NormalVideos': 0,   # Normal\n",
    "    'RoadAccidents': 1,  # Low danger\n",
    "    'Robbery': 3,        # High danger\n",
    "    'Shooting': 3,       # High danger\n",
    "    'Shoplifting': 1,    # Low danger\n",
    "    'Stealing': 2,       # Medium danger\n",
    "    'Vandalism': 2       # Medium danger\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\Harshi\\Downloads\\mixkit-boxers-hitting-in-a-fight-40967-medium.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "    print(predictions)\n",
    "\n",
    "#     # Convert predictions to class labels using class_mapping\n",
    "#     predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "#     # Check if the predicted label index is in class_mapping\n",
    "#     if predicted_label_index in class_mapping:\n",
    "#         predicted_label = class_mapping[predicted_label_index]\n",
    "#     else:\n",
    "# #         print(f\"Unexpected predicted label index: {predicted_label_index}\")\n",
    "#         predicted_label = 0\n",
    "\n",
    "    predicted_label_index=np.argmax(predictions)\n",
    "    \n",
    "    keys_list=list(class_mapping.keys())\n",
    "    \n",
    "    key_at_index = keys_list[predicted_label_index]\n",
    "    value_at_index = class_mapping[key_at_index]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {key_at_index}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c8bb9b",
   "metadata": {},
   "source": [
    "# NEW CORRECT CODE WITH CLASS IMBALANCE CORRECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4469c25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,112\n",
      "Trainable params: 228,928\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78049 images belonging to 14 classes.\n",
      "Found 19414 images belonging to 14 classes.\n",
      "Class Weights: {0: 1.0538617337294085, 1: 0.6890283736779843, 2: 0.9449031476997579, 3: 1.51000232162204, 4: 0.8280006789586472, 5: 1.4028506722266159, 6: 0.5958029893586162, 7: 1.7421651785714285, 8: 0.7941493691493692, 9: 0.43601818953766397, 10: 2.2773401027077496, 11: 1.8466142999100932, 12: 1.6996733449477353, 13: 1.7106255205365362}\n",
      "Epoch 1/20\n",
      "4879/4879 [==============================] - ETA: 0s - loss: 2.1550 - accuracy: 0.2976"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 158\u001b[0m\n\u001b[0;32m    152\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Train the model with class weights\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the calculated class weights\u001b[39;49;00m\n\u001b[0;32m    165\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m    168\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_set, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_set))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1432\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1433\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1434\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1443\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1444\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1445\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1457\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1458\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1755\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1756\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1757\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1758\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\OUTPUT_AHAR\\Train'\n",
    "validation1_data = r'D:\\OUTPUT_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(training_set.classes), y=training_set.classes)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Model compilation with class weights\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with class weights\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set),\n",
    "    class_weight=class_weight_dict  # Pass the calculated class weights\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a130a1",
   "metadata": {},
   "source": [
    "# CODE FOR ANOTHER TYPE - 4 CLASSES : NORMAL,LOW,MED,HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd1156c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HighDanger', 'LowDanger', 'MediumDanger', 'Normal']\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 4)    256         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 4)            0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 4)            0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 229,472\n",
      "Trainable params: 228,288\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78049 images belonging to 4 classes.\n",
      "Found 19414 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "4879/4879 [==============================] - 2297s 469ms/step - loss: 0.9706 - accuracy: 0.5635 - val_loss: 1.3513 - val_accuracy: 0.4708\n",
      "Epoch 2/20\n",
      "4879/4879 [==============================] - 226s 46ms/step - loss: 0.8615 - accuracy: 0.6318 - val_loss: 1.5832 - val_accuracy: 0.4687\n",
      "Epoch 3/20\n",
      "4879/4879 [==============================] - 230s 47ms/step - loss: 0.8052 - accuracy: 0.6731 - val_loss: 1.5911 - val_accuracy: 0.4707\n",
      "Epoch 4/20\n",
      "4879/4879 [==============================] - 233s 48ms/step - loss: 0.7516 - accuracy: 0.7065 - val_loss: 2.0814 - val_accuracy: 0.3580\n",
      "Epoch 5/20\n",
      "4879/4879 [==============================] - 238s 49ms/step - loss: 0.7065 - accuracy: 0.7395 - val_loss: 1.8028 - val_accuracy: 0.4208\n",
      "Epoch 6/20\n",
      "4879/4879 [==============================] - 241s 49ms/step - loss: 0.6755 - accuracy: 0.7579 - val_loss: 1.7367 - val_accuracy: 0.4599\n",
      "Epoch 7/20\n",
      "4879/4879 [==============================] - 242s 50ms/step - loss: 0.6501 - accuracy: 0.7742 - val_loss: 1.5829 - val_accuracy: 0.4603\n",
      "Epoch 8/20\n",
      "4879/4879 [==============================] - 243s 50ms/step - loss: 0.6252 - accuracy: 0.7902 - val_loss: 2.5531 - val_accuracy: 0.4626\n",
      "Epoch 9/20\n",
      "4879/4879 [==============================] - 244s 50ms/step - loss: 0.6104 - accuracy: 0.8003 - val_loss: 1.8552 - val_accuracy: 0.4852\n",
      "Epoch 10/20\n",
      "4879/4879 [==============================] - 245s 50ms/step - loss: 0.5959 - accuracy: 0.8107 - val_loss: 1.8504 - val_accuracy: 0.4816\n",
      "Epoch 11/20\n",
      "4879/4879 [==============================] - 245s 50ms/step - loss: 0.5859 - accuracy: 0.8182 - val_loss: 2.9285 - val_accuracy: 0.4550\n",
      "Epoch 12/20\n",
      "4879/4879 [==============================] - 246s 50ms/step - loss: 0.5798 - accuracy: 0.8218 - val_loss: 4.7072 - val_accuracy: 0.4710\n",
      "Epoch 13/20\n",
      "4879/4879 [==============================] - 246s 51ms/step - loss: 0.5702 - accuracy: 0.8287 - val_loss: 1.9053 - val_accuracy: 0.4685\n",
      "Epoch 14/20\n",
      "4879/4879 [==============================] - 246s 50ms/step - loss: 0.5635 - accuracy: 0.8335 - val_loss: 2.7624 - val_accuracy: 0.4485\n",
      "Epoch 15/20\n",
      "4879/4879 [==============================] - 246s 50ms/step - loss: 0.5602 - accuracy: 0.8344 - val_loss: 1.9282 - val_accuracy: 0.5075\n",
      "Epoch 16/20\n",
      "4879/4879 [==============================] - 248s 51ms/step - loss: 0.5519 - accuracy: 0.8399 - val_loss: 1.6468 - val_accuracy: 0.4804\n",
      "Epoch 17/20\n",
      "4879/4879 [==============================] - 246s 50ms/step - loss: 0.5441 - accuracy: 0.8442 - val_loss: 2.1475 - val_accuracy: 0.4645\n",
      "Epoch 18/20\n",
      "4879/4879 [==============================] - 248s 51ms/step - loss: 0.5440 - accuracy: 0.8442 - val_loss: 2.3379 - val_accuracy: 0.4837\n",
      "Epoch 19/20\n",
      "4879/4879 [==============================] - 247s 51ms/step - loss: 0.5334 - accuracy: 0.8499 - val_loss: 1.9554 - val_accuracy: 0.4718\n",
      "Epoch 20/20\n",
      "4879/4879 [==============================] - 249s 51ms/step - loss: 0.5334 - accuracy: 0.8502 - val_loss: 2.0417 - val_accuracy: 0.4928\n",
      "304/304 [==============================] - 21s 69ms/step - loss: 2.0417 - accuracy: 0.4928\n",
      "304/304 [==============================] - 21s 68ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  HighDanger       0.44      0.32      0.37      8408\n",
      "   LowDanger       0.14      0.07      0.09      2793\n",
      "MediumDanger       0.39      0.58      0.46      7413\n",
      "      Normal       0.05      0.05      0.05       800\n",
      "\n",
      "    accuracy                           0.37     19414\n",
      "   macro avg       0.25      0.25      0.24     19414\n",
      "weighted avg       0.36      0.37      0.35     19414\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2693  598 4770  347]\n",
      " [ 887  191 1598  117]\n",
      " [2339  522 4280  272]\n",
      " [ 243   58  459   40]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "class_labels = [\n",
    "    'HighDanger', 'LowDanger', 'MediumDanger', 'Normal'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\LEVEL_AHAR\\Train'\n",
    "validation1_data = r'D:\\LEVEL_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "# skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "# layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "# skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "# layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "# skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer11 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), name='sep_conv22')(layer10)\n",
    "# layer11 = GlobalAveragePooling2D(name='gap1')(layer11)\n",
    "layer11 = Flatten(name='flatten1')(layer11)\n",
    "output = Activation('softmax', name='softmax1')(layer11)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Image data generator with augmentation and preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "# Model compilation with class weights\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with class weights\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set),\n",
    "#     class_weight=class_weight_dict  # Pass the calculated class weights\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb850b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AHAR_savedmodel_epoch20_accuracy50_4levels.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fbaaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.9901026e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.0317549e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.478962e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0619746e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0091835e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0636806e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.6344067e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.8973278e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.8217487e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.5226044e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.4373296e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.9063585e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.4919923e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.085719e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.1342405e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.000000e+00 0.000000e+00 3.974161e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.8415586e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.8008314e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.000000e+00 0.000000e+00 3.440583e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.4542864e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.7203135e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.9447836e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.000000e+00 0.000000e+00 4.046736e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.1437762e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.9024113e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.434027e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.8963722e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.1895785e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.000000e+00 0.000000e+00 3.091115e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.6417126e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0963432e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.8761808e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.8634115e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.5673653e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.553945e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.902203e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.4184995e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.7367174e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.000000e+00 0.000000e+00 2.374764e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.1059608e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0073015e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.5891502e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.000000e+00 0.000000e+00 4.051215e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.4185378e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.4141912e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.000000e+00 0.000000e+00 4.175671e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.1796232e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.9908267e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.5222685e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.3645953e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.000000e+00 0.000000e+00 4.750029e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.1762443e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.000000e+00 0.000000e+00 4.156711e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.000000e+00 0.000000e+00 4.145895e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.1873162e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.6813494e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[1.000000e+00 0.000000e+00 2.851408e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0685227e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.026821e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.9241983e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.3751947e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.803123e-16 0.000000e+00]]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.0743074e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.8756188e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.8689127e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.00000e+00 0.00000e+00 3.86608e-16 0.00000e+00]]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0497927e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.1678005e-16 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.7365278e-16 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_savedmodel_epoch20_accuracy50_4levels.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    'HighDanger':3,\n",
    "    'LowDanger': 1,\n",
    "    'MediumDanger': 2,\n",
    "    'Normal': 0\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'D:\\Anomaly-Videos-Part-1\\Stealing\\Stealing003_x264.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "    print(predictions)\n",
    "\n",
    "#     # Convert predictions to class labels using class_mapping\n",
    "#     predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "#     # Check if the predicted label index is in class_mapping\n",
    "#     if predicted_label_index in class_mapping:\n",
    "#         predicted_label = class_mapping[predicted_label_index]\n",
    "#     else:\n",
    "# #         print(f\"Unexpected predicted label index: {predicted_label_index}\")\n",
    "#         predicted_label = 0\n",
    "\n",
    "    predicted_label_index=np.argmax(predictions)\n",
    "    \n",
    "    keys_list=list(class_mapping.keys())\n",
    "    \n",
    "    key_at_index = keys_list[predicted_label_index]\n",
    "    value_at_index = class_mapping[key_at_index]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {key_at_index}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6bb35d",
   "metadata": {},
   "source": [
    "# ANOTHER TIME MODEL BUILDING WITH MORE NORMALVIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d2fa60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HighDanger', 'LowDanger', 'MediumDanger', 'Normal']\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 4)    256         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 4)            0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 4)            0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 229,472\n",
      "Trainable params: 228,288\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Found 110123 images belonging to 4 classes.\n",
      "Found 24551 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "6883/6883 [==============================] - 4224s 613ms/step - loss: 0.7090 - accuracy: 0.6646 - val_loss: 1.8165 - val_accuracy: 0.5464\n",
      "Epoch 2/20\n",
      "6883/6883 [==============================] - 337s 49ms/step - loss: 0.6470 - accuracy: 0.7013 - val_loss: 1.2125 - val_accuracy: 0.4450\n",
      "Epoch 3/20\n",
      "6883/6883 [==============================] - 330s 48ms/step - loss: 0.6259 - accuracy: 0.7188 - val_loss: 0.9094 - val_accuracy: 0.5854\n",
      "Epoch 4/20\n",
      "6883/6883 [==============================] - 339s 49ms/step - loss: 0.6104 - accuracy: 0.7301 - val_loss: 1.0808 - val_accuracy: 0.5683\n",
      "Epoch 5/20\n",
      "6883/6883 [==============================] - 351s 51ms/step - loss: 0.5944 - accuracy: 0.7434 - val_loss: 1.1198 - val_accuracy: 0.5174\n",
      "Epoch 6/20\n",
      "6883/6883 [==============================] - 363s 53ms/step - loss: 0.5820 - accuracy: 0.7544 - val_loss: 1.0471 - val_accuracy: 0.5698\n",
      "Epoch 7/20\n",
      "6883/6883 [==============================] - 357s 52ms/step - loss: 0.5702 - accuracy: 0.7619 - val_loss: 1.1213 - val_accuracy: 0.5989\n",
      "Epoch 8/20\n",
      "6883/6883 [==============================] - 350s 51ms/step - loss: 0.5562 - accuracy: 0.7735 - val_loss: 0.9901 - val_accuracy: 0.5936\n",
      "Epoch 9/20\n",
      "6883/6883 [==============================] - 366s 53ms/step - loss: 0.5472 - accuracy: 0.7807 - val_loss: 1.1480 - val_accuracy: 0.5940\n",
      "Epoch 10/20\n",
      "6883/6883 [==============================] - 354s 51ms/step - loss: 0.5389 - accuracy: 0.7870 - val_loss: 1.6048 - val_accuracy: 0.5757\n",
      "Epoch 11/20\n",
      "6883/6883 [==============================] - 359s 52ms/step - loss: 0.5321 - accuracy: 0.7937 - val_loss: 1.2847 - val_accuracy: 0.5110\n",
      "Epoch 12/20\n",
      "6883/6883 [==============================] - 358s 52ms/step - loss: 0.5213 - accuracy: 0.7993 - val_loss: 1.2084 - val_accuracy: 0.5507\n",
      "Epoch 13/20\n",
      "6883/6883 [==============================] - 354s 51ms/step - loss: 0.5146 - accuracy: 0.8064 - val_loss: 1.4363 - val_accuracy: 0.4734\n",
      "Epoch 14/20\n",
      "6883/6883 [==============================] - 369s 54ms/step - loss: 0.5104 - accuracy: 0.8076 - val_loss: 1.3369 - val_accuracy: 0.5815\n",
      "Epoch 15/20\n",
      "6883/6883 [==============================] - 359s 52ms/step - loss: 0.5054 - accuracy: 0.8135 - val_loss: 1.1365 - val_accuracy: 0.5710\n",
      "Epoch 16/20\n",
      "6883/6883 [==============================] - 352s 51ms/step - loss: 0.4978 - accuracy: 0.8179 - val_loss: 1.4165 - val_accuracy: 0.5718\n",
      "Epoch 17/20\n",
      "6883/6883 [==============================] - 352s 51ms/step - loss: 0.4923 - accuracy: 0.8206 - val_loss: 1.1619 - val_accuracy: 0.5901\n",
      "Epoch 18/20\n",
      "6883/6883 [==============================] - 358s 52ms/step - loss: 0.4924 - accuracy: 0.8215 - val_loss: 1.3610 - val_accuracy: 0.5545\n",
      "Epoch 19/20\n",
      "6883/6883 [==============================] - 355s 52ms/step - loss: 0.4887 - accuracy: 0.8246 - val_loss: 1.5816 - val_accuracy: 0.5781\n",
      "Epoch 20/20\n",
      "6883/6883 [==============================] - 363s 53ms/step - loss: 0.4867 - accuracy: 0.8259 - val_loss: 1.2898 - val_accuracy: 0.5847\n",
      "384/384 [==============================] - 29s 75ms/step - loss: 1.2898 - accuracy: 0.5847\n",
      "384/384 [==============================] - 28s 72ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  HighDanger       0.34      0.60      0.44      8408\n",
      "   LowDanger       0.10      0.02      0.04      2793\n",
      "MediumDanger       0.31      0.14      0.19      7413\n",
      "      Normal       0.24      0.23      0.24      5937\n",
      "\n",
      "    accuracy                           0.31     24551\n",
      "   macro avg       0.25      0.25      0.22     24551\n",
      "weighted avg       0.28      0.31      0.27     24551\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5076  213 1091 2028]\n",
      " [1671   61  373  688]\n",
      " [4400  191 1001 1821]\n",
      " [3634  162  746 1395]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "class_labels = [\n",
    "    'HighDanger', 'LowDanger', 'MediumDanger', 'Normal'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\LEVEL_AHAR\\Train'\n",
    "validation1_data = r'D:\\LEVEL_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Calculate class weights\n",
    "# class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(training_set.classes), y=training_set.classes)\n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "# print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Model compilation with class weights\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with class weights\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set),\n",
    "#     class_weight=class_weight_dict  # Pass the calculated class weights\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e259f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AHAR_morenormalvideos_savedmodel_epoch20_accuracy60.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70aaf83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step\n",
      "[[1.0000000e+00 4.2108092e-33 6.2044925e-11 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 9.5036955e-33 2.2455929e-11 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 2.3264513e-32 2.7786022e-11 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 2.6112559e-30 5.9486804e-10 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 3.5196123e-29 1.9439346e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 1.1983430e-28 1.3914605e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[1.0000000e+00 4.2663131e-27 4.9113185e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[1.0000000e+00 3.9672946e-26 1.6577014e-08 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 4.4130238e-26 1.7814346e-08 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 4.7063925e-26 9.3349541e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.0000000e+00 1.5588321e-27 3.9762376e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 2.5780703e-29 2.9345679e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 1.0108343e-31 2.0815354e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[1.000000e+00 1.560820e-34 8.902408e-10 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 1.3805962e-34 8.3811952e-10 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.0000000e+00 4.8078582e-37 4.5135867e-10 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.0958982e-10 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.2090628e-11 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.000000e+00 0.000000e+00 9.627148e-12 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4956122e-09 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.000000e+00 0.000000e+00 9.351919e-09 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.000000e+00 0.000000e+00 9.194559e-09 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[1.0000000e+00 2.9634015e-38 3.4624204e-08 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[9.9999988e-01 2.9609153e-38 8.1321460e-08 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[9.999999e-01 1.924530e-38 8.513319e-08 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[9.999999e-01 0.000000e+00 9.692426e-08 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[9.999999e-01 0.000000e+00 9.051082e-08 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[9.999999e-01 0.000000e+00 9.015640e-08 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 9.0270994e-08 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.00000e+00 0.00000e+00 4.68524e-10 0.00000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.615187e-10 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.0266069e-10 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.224449e-13 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.147665e-13 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.9513816e-14 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.0135632e-14 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.000000e+00 0.000000e+00 2.023944e-14 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 8.5924356e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3331698e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.2980663e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 8.3453423e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[1.000000e+00 0.000000e+00 1.501424e-15 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.6017087e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.1582563e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.000000e+00 0.000000e+00 3.575744e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.3755295e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.000000e+00 0.000000e+00 2.347169e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 5.7504304e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.00000e+00 0.00000e+00 8.73704e-16 0.00000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.1477697e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 7.0742057e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 7.2355045e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.000000e+00 0.000000e+00 1.368704e-14 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4692061e-14 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.00000000e+00 0.00000000e+00 1.36829685e-14 0.00000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.2398933e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.0710401e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.0607125e-15 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 8.7173984e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[1.000000e+00 0.000000e+00 9.091949e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.000000e+00 0.000000e+00 9.159624e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 7.0401207e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.000000e+00 0.000000e+00 6.963066e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 6.7971504e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[1.000000e+00 0.000000e+00 6.352169e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 6.0276866e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.000000e+00 0.000000e+00 4.785239e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 5.1570124e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.000000e+00 0.000000e+00 5.044589e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.000000e+00 0.000000e+00 5.079114e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 4.3713438e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.7689522e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.7839341e-16 0.0000000e+00]]\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.000000e+00 0.000000e+00 3.410346e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.3887927e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.4078232e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 3.0635286e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.9660698e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.8262194e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.8235256e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.000000e+00 0.000000e+00 2.545438e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[1.000000e+00 0.000000e+00 2.504465e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.4692982e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.4305978e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.4472142e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 2.1856665e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.9764995e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.9787022e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.9832968e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.9545607e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.000000e+00 0.000000e+00 2.030128e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.7304035e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4357484e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3874195e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3584995e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3966591e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4059069e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4779203e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3846224e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3994537e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4222892e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4306584e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3817151e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4107526e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3403492e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.2993983e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3186028e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3440151e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3090403e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.2586899e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3437791e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3441586e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3605013e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[1.000000e+00 0.000000e+00 1.314294e-16 0.000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.3627867e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 1.4213292e-16 0.0000000e+00]]\n",
      "0\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[1.000000e+00 0.000000e+00 1.328448e-16 0.000000e+00]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_morenormalvideos_savedmodel_epoch20_accuracy60.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    'HighDanger':3,\n",
    "    'LowDanger': 1,\n",
    "    'MediumDanger': 2,\n",
    "    'Normal': 0\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'D:\\Anomaly-Videos-Part-1\\Vandalism\\Vandalism001_x264.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "    print(predictions)\n",
    "\n",
    "#     # Convert predictions to class labels using class_mapping\n",
    "#     predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "#     # Check if the predicted label index is in class_mapping\n",
    "#     if predicted_label_index in class_mapping:\n",
    "#         predicted_label = class_mapping[predicted_label_index]\n",
    "#     else:\n",
    "# #         print(f\"Unexpected predicted label index: {predicted_label_index}\")\n",
    "#         predicted_label = 0\n",
    "\n",
    "    predicted_label_index=np.argmax(predictions)\n",
    "    print(predicted_label_index)\n",
    "    \n",
    "    keys_list=list(class_mapping.keys())\n",
    "    \n",
    "    key_at_index = keys_list[predicted_label_index]\n",
    "    value_at_index = class_mapping[key_at_index]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {value_at_index}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46577110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 131us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_morenormalvideos_savedmodel_epoch20_accuracy60.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Get the number of classes in the model\n",
    "num_classes = model.output_shape[1]\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    i: i // (num_classes // 4) for i in range(num_classes)\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'D:\\Anomaly-Videos-Part-1\\Vandalism\\Vandalism001_x264.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    predicted_label = class_mapping[np.argmax(predictions)]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {predicted_label}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#     print(predicted_label)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c1eac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 823us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_morenormalvideos_savedmodel_epoch20_accuracy60.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Get the number of classes in the model\n",
    "num_classes = model.output_shape[1]\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    'HighDanger': 3,\n",
    "    'LowDanger': 1,\n",
    "    'MediumDanger': 2,\n",
    "    'Normal': 0\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'D:\\Anomaly-Videos-Part-1\\Vandalism\\Vandalism001_x264.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    predicted_label = class_mapping[max(class_mapping, key=lambda k: predictions[0][class_mapping[k]])]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {predicted_label}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424be64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24551 images belonging to 4 classes.\n",
      "384/384 [==============================] - 71s 130ms/step - loss: 1.2898 - accuracy: 0.5847\n",
      "384/384 [==============================] - 24s 63ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  HighDanger       0.48      0.84      0.61      8408\n",
      "   LowDanger       0.10      0.02      0.04      2793\n",
      "MediumDanger       0.41      0.18      0.25      7413\n",
      "      Normal       1.00      1.00      1.00      5937\n",
      "\n",
      "    accuracy                           0.58     24551\n",
      "   macro avg       0.50      0.51      0.47     24551\n",
      "weighted avg       0.54      0.58      0.53     24551\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7032  192 1184    0]\n",
      " [2032   62  699    0]\n",
      " [5712  373 1328    0]\n",
      " [   5    0    0 5932]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class_labels = [\n",
    "    'HighDanger', 'LowDanger', 'MediumDanger', 'Normal'\n",
    "]\n",
    "IMG_SIZE = 160\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_morenormalvideos_savedmodel_epoch20_accuracy60.h5'  # Replace with the actual path to your saved model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Directory paths for test data\n",
    "test_data_dir =  r'D:\\LEVEL_AHAR\\Test'  # Replace with the path to your test data\n",
    "\n",
    "# Number of images in your test set\n",
    "num_test_samples = 100  # Replace with the actual number of test samples\n",
    "\n",
    "# Batch size for evaluation\n",
    "batch_size = 64\n",
    "\n",
    "# Create a test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=class_labels,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False,\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_generator, steps=len(test_generator))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_generator, steps=len(test_generator))\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c79a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45baa9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score       support\n",
      "HighDanger     0.475746  0.836346  0.606494   8408.000000\n",
      "LowDanger      0.098884  0.022198  0.036257   2793.000000\n",
      "MediumDanger   0.413578  0.179145  0.250000   7413.000000\n",
      "Normal         1.000000  0.999158  0.999579   5937.000000\n",
      "accuracy       0.584661  0.584661  0.584661      0.584661\n",
      "macro avg      0.497052  0.509212  0.473083  24551.000000\n",
      "weighted avg   0.540879  0.584661  0.529038  24551.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(\"Classification Report:\")\n",
    "classification_rep = classification_report(true_labels, predicted_labels, target_names=class_labels, output_dict=True)\n",
    "classification_df = pd.DataFrame(classification_rep).transpose()\n",
    "print(classification_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a52e7d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate percentages from the confusion matrix\n",
    "conf_matrix_percentage = conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_percentage, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(\"Confusion Matrix (Percentage)\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d69cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/YAAAK7CAYAAABYqRRSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB09UlEQVR4nOzde3zP9f//8fvbzpvtzTY71cYwQ86nmT5lcj4k9fkk0T5IKEULOaRCiVKhKCFMDunzqfh23CcKlbOxhFF9olEbVrNhR9vr90c/709vm8Nm896L2/Vy2eXj/Xw9Xs/X4/X28u5z3+vwthiGYQgAAAAAAJhSFUc3AAAAAAAAyo5gDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwCodOLj42WxWGw/zs7OCg4OVr9+/fTjjz+Wac6NGzfKYrFo48aNpV73wIEDmjJlio4cOVJs2aBBg1SrVq0y9VSeBg0apKpVq15RrcVi0ZQpUyqkj9dff10Wi0WNGjWqkPkrs71792rw4MEKDw+Xu7u7qlatqhYtWmjmzJn6448/bHUxMTGKiYlxXKMAgOuOs6MbAADgYpYuXar69esrNzdXmzdv1gsvvKANGzbo4MGDql69+jXr48CBA5o6dapiYmKKhfhnnnlGjz/++DXrpTxs3bpVN998c4XMvWTJEknS/v37tX37dkVFRVXIdiqbRYsWacSIEYqMjNSTTz6phg0bqqCgQLt27dJbb72lrVu3as2aNY5uEwBwnSLYAwAqrUaNGqlVq1aS/jzLWVhYqMmTJ2vt2rUaPHiwg7v7U506dRzdQqm1bdu2QubdtWuXvvvuO/Xs2VOffvqpFi9efEME+61bt+qRRx5R586dtXbtWrm5udmWde7cWWPGjFFCQoIDOwQAXO+4FB8AYBrnQ/7x48ftxnft2qXevXvL19dX7u7uat68uf71r39ddr5du3apX79+qlWrljw8PFSrVi3df//9+uWXX2w18fHxuvfeeyVJHTp0sN0eEB8fL6nkS/Fzc3M1ceJEhYeHy9XVVTfddJMeffRRnTp1yq6uVq1a6tWrlxISEtSiRQt5eHiofv36trPe52VnZ2vs2LG2S7x9fX3VqlUrvfvuu8X26aefflKPHj1UtWpVhYaGasyYMcrLy7OrufBS/PO3Pqxbt06DBw+Wr6+vvLy8dOedd+rnn3++7Pt43uLFiyVJL774otq1a6fVq1crOzvbrubIkSOyWCx6+eWX9dJLL9ne+5iYGP3www8qKCjQhAkTFBISIqvVqrvvvlsnTpywm6OoqEgzZ85U/fr15ebmpoCAAP3zn//UsWPH7OpiYmLUqFEj7dy5U7fddps8PT1Vu3ZtvfjiiyoqKrKr3b9/v7p06SJPT0/VqFFDjz76qD799NMrun1j+vTpslgsWrhwoV2oP8/V1VW9e/e+5BxTp05VVFSUfH195ePjoxYtWmjx4sUyDMOu7quvvlJMTIz8/Pzk4eGhsLAw/f3vf7d7n+fPn6+mTZuqatWq8vb2Vv369fXUU0/ZzZOWlqbhw4fr5ptvlqurq8LDwzV16lSdO3fOru5K5gIAOB5n7AEApnH48GFJUr169WxjGzZsULdu3RQVFaW33npLVqtVq1ev1n333afs7GwNGjToovMdOXJEkZGR6tevn3x9fZWamqr58+erdevWOnDggPz9/dWzZ09Nnz5dTz31lN544w21aNFC0sXP1BuGoT59+ujLL7/UxIkTddttt2nv3r2aPHmytm7dqq1bt9qFv++++05jxozRhAkTFBgYqLfffltDhgxR3bp1dfvtt0uSRo8ereXLl2vatGlq3ry5zp49q3379un333+323ZBQYF69+6tIUOGaMyYMfr666/1/PPPy2q16tlnn73s+ztkyBB17txZq1at0tGjR/X0008rJiZGe/fuVbVq1S65bk5Ojt599121bt1ajRo10oMPPqiHHnpI//73vzVw4MBi9W+88YaaNGmiN954Q6dOndKYMWN05513KioqSi4uLlqyZIl++eUXjR07Vg899JA++ugj27qPPPKIFi5cqMcee0y9evXSkSNH9Mwzz2jjxo3avXu3/P39bbVpaWkaMGCAxowZo8mTJ2vNmjWaOHGiQkJC9M9//lOSlJqaqvbt28vLy0vz589XQECA3n33XT322GOXfc8KCwv11VdfqWXLlgoNDb1s/cUcOXJEw4cPV1hYmCRp27ZtGjlypH799Vfb392RI0fUs2dP3XbbbVqyZImqVaumX3/9VQkJCcrPz5enp6dWr16tESNGaOTIkXrllVdUpUoV/fTTTzpw4IDde9KmTRtVqVJFzz77rOrUqaOtW7dq2rRpOnLkiJYuXSpJVzQXAKCSMAAAqGSWLl1qSDK2bdtmFBQUGKdPnzYSEhKMoKAg4/bbbzcKCgpstfXr1zeaN29uN2YYhtGrVy8jODjYKCwsNAzDMDZs2GBIMjZs2HDR7Z47d844c+aM4eXlZbz22mu28X//+98XXXfgwIFGzZo1ba8TEhIMScbMmTPt6t577z1DkrFw4ULbWM2aNQ13d3fjl19+sY3l5OQYvr6+xvDhw21jjRo1Mvr06XPRvs/3Icn417/+ZTfeo0cPIzIy0m5MkjF58mTb6/Pv9913321Xt3nzZkOSMW3atEtu2zAM45133jEkGW+99ZZhGIZx+vRpo2rVqsZtt91mV3f48GFDktG0aVPb341hGMacOXMMSUbv3r3t6uPi4gxJRmZmpmEYhpGcnGxIMkaMGGFXt337dkOS8dRTT9nG2rdvb0gytm/fblfbsGFDo2vXrrbXTz75pGGxWIz9+/fb1XXt2vWyx0xaWpohyejXr99Fay7Uvn17o3379hddXlhYaBQUFBjPPfec4efnZxQVFRmGYRjvv/++IclISkq66LqPPfaYUa1atUtuf/jw4UbVqlXtjjvDMIxXXnnFkGR7H65kLgBA5cCl+ACASqtt27ZycXGRt7e3unXrpurVq+v//u//5Oz85wVnP/30kw4ePKgBAwZIks6dO2f76dGjh1JTU3Xo0KGLzn/mzBmNHz9edevWlbOzs5ydnVW1alWdPXtWycnJZer5q6++kqRiVwrce++98vLy0pdffmk33qxZM9tZWklyd3dXvXr17G4HaNOmjT7//HNNmDBBGzduVE5OTonbtlgsuvPOO+3GmjRpYjfXpZx/H89r166datasqQ0bNlx23cWLF8vDw0P9+vWTJFWtWlX33nuvvvnmmxK/yaBHjx6qUuV//zekQYMGkqSePXva1Z0fT0lJkSRbLxe+v23atFGDBg2Kvb9BQUFq06aN3diF78mmTZvUqFEjNWzY0K7u/vvvv/ROl6OvvvpKnTp1ktVqlZOTk1xcXPTss8/q999/t92K0KxZM7m6umrYsGFatmxZibdJtGnTRqdOndL999+v//u//1N6enqxmk8++UQdOnRQSEiI3b+Z7t27S/rz/bjSuQAAlQPBHgBQab3zzjvauXOnvvrqKw0fPlzJycl2Yev8vfZjx46Vi4uL3c+IESMk6ZJhpH///po3b54eeugh/ec//9GOHTu0c+dO1ahR46Lh+XJ+//13OTs7q0aNGnbjFotFQUFBxS6f9/PzKzaHm5ub3fZff/11jR8/XmvXrlWHDh3k6+urPn36FAvMnp6ecnd3LzZXbm7uFfUeFBRU4tiFPV/op59+0tdff62ePXvKMAydOnVKp06d0j/+8Q9JKvbMAEny9fW1e+3q6nrJ8fP7cL6X4ODgYnOGhISU6f39/fffFRgYWKyupLEL+fv7y9PT03abSFns2LFDXbp0kfTn0/U3b96snTt3atKkSZJk67VOnTpav369AgIC9Oijj6pOnTqqU6eOXnvtNdtcsbGxttsY/v73vysgIEBRUVFat26dreb48eP6+OOPi/2bueWWWyT979/MlcwFAKgcuMceAFBpNWjQwPbAvA4dOqiwsFBvv/223n//ff3jH/+w3Us9ceJE3XPPPSXOERkZWeJ4ZmamPvnkE02ePFkTJkywjefl5dl953hp+fn56dy5czp58qRduDcMQ2lpaWrdunWp5/Ty8tLUqVM1depUHT9+3Hb2/s4779TBgwfL3OuF0tLSShyrW7fuJddbsmSJDMPQ+++/r/fff7/Y8mXLlmnatGlycnK66h7PB/XU1NRiX9n322+/2d1fX5o5L3wgo1Ty+3EhJycndezYUZ9//rmOHTtWpq8RXL16tVxcXPTJJ5/Y/WJm7dq1xWpvu+023XbbbSosLNSuXbs0d+5cxcXFKTAw0Ha1xODBgzV48GCdPXtWX3/9tSZPnqxevXrphx9+UM2aNeXv768mTZrohRdeKLGfkJAQ258vNxcAoHLgjD0AwDRmzpyp6tWr69lnn1VRUZEiIyMVERGh7777Tq1atSrxx9vbu8S5LBaLDMMo9hTzt99+W4WFhXZj52uu5Cx+x44dJUkrVqywG//ggw909uxZ2/KyCgwM1KBBg3T//ffr0KFDxZ46fzVWrlxp93rLli365ZdfFBMTc9F1CgsLtWzZMtWpU0cbNmwo9jNmzBilpqbq888/L5ce77jjDknF39+dO3cqOTm5TO9v+/bttW/fvmIPhVu9evUVrT9x4kQZhqGhQ4cqPz+/2PKCggJ9/PHHF13fYrHI2dnZ7hcfOTk5Wr58+UXXcXJyUlRUlN544w1J0u7du4vVeHl5qXv37po0aZLy8/O1f/9+SVKvXr20b98+1alTp8R/M38N9pebCwBQOXDGHgBgGtWrV9fEiRM1btw4rVq1Sg888IAWLFig7t27q2vXrho0aJBuuukm/fHHH0pOTtbu3bv173//u8S5fHx8dPvtt+vll1+Wv7+/atWqpU2bNmnx4sXFngDfqFEjSdLChQvl7e0td3d3hYeHl3iZd+fOndW1a1eNHz9eWVlZuvXWW21PxW/evLliY2NLvd9RUVHq1auXmjRpourVqys5OVnLly9XdHS0PD09Sz3fxezatUsPPfSQ7r33Xh09elSTJk3STTfdZLutoSSff/65fvvtN7300ksl/gKgUaNGmjdvnhYvXqxevXpddY+RkZEaNmyY5s6dqypVqqh79+62p+KHhobqiSeeKPWccXFxWrJkibp3767nnntOgYGBWrVqle1qiL8+C6Ak0dHRmj9/vkaMGKGWLVvqkUce0S233KKCggLt2bNHCxcuVKNGjYo9/+C8nj17atasWerfv7+GDRum33//Xa+88kqxXzq99dZb+uqrr9SzZ0+FhYUpNzfXdptDp06dJElDhw6Vh4eHbr31VgUHBystLU0zZsyQ1Wq1XS3y3HPPad26dWrXrp1GjRqlyMhI5ebm6siRI/rss8/01ltv6eabb76iuQAAlYRDH90HAEAJzj+lfefOncWW5eTkGGFhYUZERIRx7tw5wzAM47vvvjP69u1rBAQEGC4uLkZQUJBxxx132J7QbhglPxX/2LFjxt///nejevXqhre3t9GtWzdj3759Rs2aNY2BAwfabXfOnDlGeHi44eTkZEgyli5dahhG8afin+9x/PjxRs2aNQ0XFxcjODjYeOSRR4yMjAy7upo1axo9e/Ysto8XPjV9woQJRqtWrYzq1asbbm5uRu3atY0nnnjCSE9Pt9UMHDjQ8PLyKjbX5MmTjQv/c6+LPBX/iy++MGJjY41q1aoZHh4eRo8ePYwff/yx2Jx/1adPH8PV1dU4ceLERWv69etnODs7G2lpaban4r/88st2Nef/fv7973/bjZd0LBQWFhovvfSSUa9ePcPFxcXw9/c3HnjgAePo0aN267Zv39645ZZbivVT0t/Zvn37jE6dOhnu7u6Gr6+vMWTIEGPZsmWGJOO777675HtwXlJSkjFw4EAjLCzMcHV1Nby8vIzmzZsbzz77rN37U9JT8ZcsWWJERkba/n5nzJhhLF682JBkHD582DAMw9i6datx9913GzVr1jTc3NwMPz8/o3379sZHH31km2fZsmVGhw4djMDAQMPV1dUICQkx+vbta+zdu9dueydPnjRGjRplhIeHGy4uLoavr6/RsmVLY9KkScaZM2dKNRcAwPEshmEYDvqdAgAAqATi4+M1ePBg7dy50/ZMA0jDhg3Tu+++q99//932ED8AACojLsUHAAA3vOeee04hISGqXbu2zpw5o08++URvv/22nn76aUI9AKDSI9gDAIAbnouLi15++WUdO3ZM586dU0REhGbNmqXHH3/c0a0BAHBZXIoPAAAAAICJ8XV3AAAAAACYGMEeAAAAAAATI9gDAAAAAGBiPDzvChUVFem3336Tt7e3LBaLo9sBAAAAAFznDMPQ6dOnFRISoipVLn5enmB/hX777TeFhoY6ug0AAAAAwA3m6NGjuvnmmy+6nGB/hby9vSX9+Yb6+Pg4uBsAAAAAwPUuKytLoaGhtjx6MQT7K3T+8nsfHx+CPQAAAADgmrnc7eA8PA8AAAAAABMj2AMAAAAAYGIEewAAAAAATIx77AEAAADgAoZh6Ny5cyosLHR0K7iOOTk5ydnZ+aq/Up1gDwAAAAB/kZ+fr9TUVGVnZzu6FdwAPD09FRwcLFdX1zLPQbAHAAAAgP+vqKhIhw8flpOTk0JCQuTq6nrVZ1OBkhiGofz8fJ08eVKHDx9WRESEqlQp293yBHsAAAAA+P/y8/NVVFSk0NBQeXp6OrodXOc8PDzk4uKiX375Rfn5+XJ3dy/TPDw8DwAAAAAuUNYzp0BplcexxtEKAAAAAICJcSk+AAAAAFyBlJQUpaenX5Nt+fv7Kyws7JpsC+ZHsAcAAACAy0hJSVH9+g2Uk3NtnpTv4eGpgweTyz3cx8fHKy4uTqdOnbridQYNGqRTp05p7dq15doLyg/BHgAAAAAuIz09XTk52Yp6cLJ8gmtV6LayUo9o+5KpSk9PL1Wwv1gA37hxozp06KCMjAzdd9996tGjRzl3LMXExGjTpk2SJFdXV/n7+6tFixYaPHiw7rnnnnLfHuwR7AEAAADgCvkE15JvWKSj2ygzDw8PeXh4VMjcQ4cO1XPPPaeCggL9+uuvWrNmjfr166dBgwZp4cKFFbLN8lRYWCiLxWLKByear2MAAAAAQJnEx8erWrVqdmPTpk1TQECAvL299dBDD2nChAlq1qxZsXVfeeUVBQcHy8/PT48++qgKCgrslnt6eiooKEihoaFq27atXnrpJS1YsECLFi3S+vXrbXXjx49XvXr15Onpqdq1a+uZZ56xm2vKlClq1qyZli9frlq1aslqtapfv346ffq0reb06dMaMGCAvLy8FBwcrNmzZysmJkZxcXG2mvz8fI0bN0433XSTvLy8FBUVpY0bNxZ7Lz755BM1bNhQbm5u+uWXX8r2xjoYwR4AAAAAblArV67UCy+8oJdeekmJiYkKCwvT/Pnzi9Vt2LBB//3vf7VhwwYtW7ZM8fHxio+Pv+z8AwcOVPXq1fXhhx/axry9vRUfH68DBw7otdde06JFizR79my79f773/9q7dq1+uSTT/TJJ59o06ZNevHFF23LR48erc2bN+ujjz7SunXr9M0332j37t12cwwePFibN2/W6tWrtXfvXt17773q1q2bfvzxR1tNdna2ZsyYobffflv79+9XQEDAlb51lQqX4gMAAADAdeKTTz5R1apV7cYKCwsvWj937lwNGTJEgwcPliQ9++yz+uKLL3TmzBm7uurVq2vevHlycnJS/fr11bNnT3355ZcaOnToJfupUqWK6tWrpyNHjtjGnn76adufa9WqpTFjxui9997TuHHjbONFRUWKj4+Xt7e3JCk2NlZffvmlXnjhBZ0+fVrLli3TqlWr1LFjR0nS0qVLFRISYlv/v//9r959910dO3bMNj527FglJCRo6dKlmj59uiSpoKBAb775ppo2bXrJ/ajsCPYAAAAAcJ3o0KFDsTPu27dv1wMPPFBi/aFDhzRixAi7sTZt2uirr76yG7vlllvk5ORkex0cHKzvv//+inoyDEMWi8X2+v3339ecOXP0008/6cyZMzp37px8fHzs1qlVq5Yt1J/f3okTJyRJP//8swoKCtSmTRvbcqvVqsjI/z37YPfu3TIMQ/Xq1bObNy8vT35+frbXrq6uatKkyRXtR2VGsAcAAACA64SXl5fq1q1rN3bs2LFLrvPX0C39GcQv5OLiUmydoqKiy/ZTWFioH3/8Ua1bt5Ykbdu2Tf369dPUqVPVtWtXWa1WrV69Wq+++uoVb+98f5fqu6ioSE5OTkpMTLT7hYQkuysaPDw8is1jRgR7AAAAALhBRUZGaseOHYqNjbWN7dq1q9zmX7ZsmTIyMvT3v/9dkrR582bVrFlTkyZNstWU9oF1derUkYuLi3bs2KHQ0FBJUlZWln788Ue1b99ektS8eXMVFhbqxIkTuu2228ppbyovgj0AAAAAXKGs1CPXxTbOGzlypIYOHapWrVqpXbt2eu+997R3717Vrl271HNlZ2crLS1N586d06+//qoPP/xQs2fP1iOPPKIOHTpIkurWrauUlBStXr1arVu31qeffqo1a9aUajve3t4aOHCgnnzySfn6+iogIECTJ09WlSpVbGff69WrpwEDBuif//ynXn31VTVv3lzp6en66quv1LhxY/Xo0aPU+1eZEewBAAAA4DL8/f3l4eGp7UumXpPteXh4yt/fv8K3M2DAAP38888aO3ascnNz1bdvXw0aNEg7duwo9VyLFi3SokWL5OrqKj8/P7Vs2VLvvfee7r77blvNXXfdpSeeeEKPPfaY8vLy1LNnTz3zzDOaMmVKqbY1a9YsPfzww+rVq5d8fHw0btw4HT16VO7u7raapUuXatq0aRozZox+/fVX+fn5KTo6+roL9ZJkMUq6gQLFZGVlyWq1KjMzs9iDHQAAAABcH3Jzc3X48GGFh4fbhURJSklJUXp6+jXpw9/fX2FhYddkWxfq3LmzgoKCtHz5codsvyzOnj2rm266Sa+++qqGDBni6HZK5VLH3JXmUM7YAwAAAMAVCAsLc1jYrijZ2dl666231LVrVzk5Oendd9/V+vXrtW7dOke3dkl79uzRwYMH1aZNG2VmZuq5556T9OcVATcigj0AAAAA3KAsFos+++wzTZs2TXl5eYqMjNQHH3ygTp06Obq1y3rllVd06NAhubq6qmXLlvrmm2+uye0LlRHBHgAAAABuUB4eHlq/fr2j2yi15s2bKzEx0dFtVBoODfa1atUq8asNRowYoTfeeEOGYWjq1KlauHChMjIyFBUVpTfeeEO33HKLrTYvL09jx47Vu+++q5ycHHXs2FFvvvmmbr75ZltNRkaGRo0apY8++kiS1Lt3b82dO1fVqlWr8H10hGt5709pOPI+IQAAAAC4Xjk02O/cuVOFhYW21/v27VPnzp117733SpJmzpypWbNmKT4+XvXq1dO0adPUuXNnHTp0SN7e3pKkuLg4ffzxx1q9erX8/Pw0ZswY9erVS4mJiXJycpIk9e/fX8eOHVNCQoIkadiwYYqNjdXHH398jfe44qWkpKh+/QbKycl2dCvFeHh46uDBZMI9AAAAAJQjhwb7GjVq2L1+8cUXVadOHbVv316GYWjOnDmaNGmS7rnnHknSsmXLFBgYqFWrVmn48OHKzMzU4sWLtXz5cts9ICtWrFBoaKjWr1+vrl27Kjk5WQkJCdq2bZuioqIk/fk1DNHR0Tp06JAiIyOv7U5XsPT0dOXkZCvqwcnyCa7l6HZsslKPaPuSqUpPTyfYAwAAAEA5qjT32Ofn52vFihUaPXq0LBaLfv75Z6WlpalLly62Gjc3N7Vv315btmzR8OHDlZiYqIKCAruakJAQNWrUSFu2bFHXrl21detWWa1WW6iXpLZt28pqtWrLli0XDfZ5eXnKy8uzvc7KyqqAva44PsG15Bt2ff3SAgAAAABQXBVHN3De2rVrderUKQ0aNEiSlJaWJkkKDAy0qwsMDLQtS0tLk6urq6pXr37JmoCAgGLbCwgIsNWUZMaMGbJarbaf0NDQMu8bAAAAAAAVpdKcsV+8eLG6d++ukJAQu3GLxWL32jCMYmMXurCmpPrLzTNx4kSNHj3a9jorK4twDwAAANzAruVDqnnwNEqjUgT7X375RevXr9eHH35oGwsKCpL05xn34OBg2/iJEydsZ/GDgoKUn5+vjIwMu7P2J06cULt27Ww1x48fL7bNkydPFrsa4K/c3Nzk5uZ2dTsGAAAA4LqQkpKiBvUjlZ2Te0225+nhruSDhwj3uCKVItgvXbpUAQEB6tmzp20sPDxcQUFBWrdunZo3by7pz/vwN23apJdeekmS1LJlS7m4uGjdunXq27evJCk1NVX79u3TzJkzJUnR0dHKzMzUjh071KZNG0nS9u3blZmZaQv/AAAAAHAp6enpys7J1YphzdQguGqFbis59YweWJhU6gdPDxo0SKdOndLatWsrrjlJGzduVIcOHST9eXW0t7e3ateurc6dO+uJJ56wOzGLa8Phwb6oqEhLly7VwIED5ez8v3YsFovi4uI0ffp0RUREKCIiQtOnT5enp6f69+8vSbJarRoyZIjGjBkjPz8/+fr6auzYsWrcuLHtKfkNGjRQt27dNHToUC1YsEDSn19316tXr+vuifgAAAAAKlaD4KpqUcvq6DYqhUOHDsnHx0dZWVnavXu3Zs6cqcWLF2vjxo1q3Lixo9u7rPz8fLm6ujq6jXLh8IfnrV+/XikpKXrwwQeLLRs3bpzi4uI0YsQItWrVSr/++qu++OIL23fYS9Ls2bPVp08f9e3bV7feeqs8PT318ccf277DXpJWrlypxo0bq0uXLurSpYuaNGmi5cuXX5P9AwAAAABH27Rpk9q0aSM3NzcFBwdrwoQJOnfunCTp448/VrVq1VRUVCRJSkpKksVi0ZNPPmlbf/jw4br//vvt5gwICFBQUJDq1aunfv36afPmzapRo4YeeeQRW83OnTvVuXNn+fv7y2q1qn379tq9e7fdPBaLRW+//bbuvvtueXp6KiIiQh999JFdzUcffaSIiAh5eHioQ4cOWrZsmSwWi06dOmWr2bJli26//XZ5eHgoNDRUo0aN0tmzZ23La9WqpWnTpmnQoEGyWq0aOnTo1b2plYjDg32XLl1kGIbq1atXbJnFYtGUKVOUmpqq3Nxcbdq0SY0aNbKrcXd319y5c/X7778rOztbH3/8cbGH3Pn6+mrFihXKyspSVlaWVqxYoWrVqlXkbgEAAABApfDrr7+qR48eat26tb777jvNnz9fixcv1rRp0yRJt99+u06fPq09e/ZI+vOXAP7+/tq0aZNtjo0bN6p9+/aX3I6Hh4cefvhhbd68WSdOnJAknT59WgMHDtQ333yjbdu2KSIiQj169NDp06ft1p06dar69u2rvXv3qkePHhowYID++OMPSdKRI0f0j3/8Q3369FFSUpKGDx+uSZMm2a3//fffq2vXrrrnnnu0d+9evffee/r222/12GOP2dW9/PLLatSokRITE/XMM8+U4d2snBwe7AEAAAAAFefNN99UaGio5s2bp/r166tPnz6aOnWqXn31VRUVFclqtapZs2bauHGjpD9D/BNPPKHvvvtOp0+fVlpamn744QfFxMRcdlv169eX9GcYl6Q77rhDDzzwgBo0aKAGDRpowYIFys7OtvulgfTn8wHuv/9+1a1bV9OnT9fZs2e1Y8cOSdJbb72lyMhIvfzyy4qMjFS/fv1sX5N+3ssvv6z+/fsrLi5OERERateunV5//XW98847ys393wMP77jjDo0dO1Z169ZV3bp1y/aGVkIEewAAAAC4jiUnJys6Otru675vvfVWnTlzRseOHZMkxcTEaOPGjTIMQ998843uuusuNWrUSN9++602bNigwMBAW2i/FMMwJP3vK8dPnDihhx9+WPXq1ZPVapXVatWZM2eUkpJit16TJk1sf/by8pK3t7ftrP+hQ4fUunVru/rzD0Y/LzExUfHx8apatartp2vXrioqKtLhw4dtda1atbrsPpiRwx+eBwAAAACoOIZh2IX682PS/wJ4TEyMFi9erO+++05VqlRRw4YN1b59e23atEkZGRmXvQz/vOTkZEl/3s8u/Xkm/uTJk5ozZ45q1qwpNzc3RUdHKz8/3249FxcXu9cWi8V2z/+l+j+vqKhIw4cP16hRo4r19NdvFvDy8rqi/TAbgj0AAAAAXMcaNmyoDz74wC4gb9myRd7e3rrpppsk/e8++zlz5qh9+/ayWCxq3769ZsyYoYyMDD3++OOX3U5OTo4WLlyo22+/XTVq1JAkffPNN3rzzTfVo0cPSdLRo0eVnp5eqv7r16+vzz77zG5s165ddq9btGih/fv3X1eX15cGwR4AAAAArlBy6plKvY3MzEwlJSXZjQ0bNkxz5szRyJEj9dhjj+nQoUOaPHmyRo8erSpV/rw7+/x99itWrNBrr70m6c+wf++996qgoKDE++tPnDih3NxcnT59WomJiZo5c6bS09P14Ycf2mrq1q2r5cuXq1WrVsrKytKTTz4pDw+PUu3T8OHDNWvWLI0fP15DhgxRUlKS4uPjJf3vioPx48erbdu2evTRRzV06FB5eXkpOTlZ69at09y5c0u1PTMi2AMAAADAZfj7+8vTw10PLEy6Jtvz9HCXv79/qdfbuHGjmjdvbjc2cOBAffbZZ3ryySfVtGlT+fr6asiQIXr66aft6jp06KDdu3fbQnz16tXVsGFD/fbbb2rQoEGxbUVGRspisahq1aqqXbu2unTpotGjRysoKMhWs2TJEg0bNkzNmzdXWFiYpk+frrFjx5Zqn8LDw/X+++9rzJgxeu211xQdHa1JkybpkUcekZubm6Q/79HftGmTJk2apNtuu02GYahOnTq67777SrUts7IYF96cgBJlZWXJarUqMzNTPj4+jm7nonbv3q2WLVuq86Sl8g2LdHQ7Nn+kHNK6FwYrMTFRLVq0cHQ7AAAAQIlyc3N1+PBhhYeHy93d3W5ZSkpKqS8jLyt/f3+7e8Nh74UXXtBbb72lo0ePOrqVq3apY+5Kcyhn7AEAAADgCoSFhRG2HeTNN99U69at5efnp82bN+vll18u9h31NzKCPQAAAACgUvvxxx81bdo0/fHHHwoLC9OYMWM0ceJER7dVaRDsAQAAAACV2uzZszV79mxHt1FpVXF0AwAAAAAAoOwI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjKfiAwAAAMAVSElJUXp6+jXZlr+/v8LCwq7JtmB+BHsAAAAAuIyUlBTVb1BfOdk512R7Hp4eOph8sFKF+40bN6pDhw7KyMhQtWrVFB8fr7i4OJ06dcrRrd3wCPYAAAAAcBnp6enKyc7R7eNulzXUWqHbyjyaqa9nfq309PRSBftBgwZp2bJlGj58uN566y27ZSNGjND8+fM1cOBAxcfHl0uf9913n3r06FEuc13KkSNHFB4ebntdtWpVhYWFKSYmRnFxcYqIiKjwHio7gj0AAAAAXCFrqFX+Ef6ObuOiQkNDtXr1as2ePVseHh6SpNzcXL377rvlfvbfw8PDto1rYf369brllluUnZ2t77//Xq+99pqaNm2qjz/+WB07drxmfZRVfn6+XF1dK2RuHp4HAAAAANeJFi1aKCwsTB9++KFt7MMPP1RoaKiaN29uGzMMQzNnzlTt2rXl4eGhpk2b6v3337eb67PPPlO9evXk4eGhDh066MiRI3bL4+PjVa1aNdvrQYMGqU+fPnY1cXFxiomJsb2OiYnRyJEjFRcXp+rVqyswMFALFy7U2bNnNXjwYHl7e6tOnTr6/PPPi+2bn5+fgoKCVLt2bd11111av369oqKiNGTIEBUWFkqS/vvf/+quu+5SYGCgqlatqtatW2v9+vV289SqVUvTp0/Xgw8+KG9vb4WFhWnhwoV2NVu2bFGzZs3k7u6uVq1aae3atbJYLEpKSrLVHDhwQD169FDVqlUVGBio2NhYu2cwxMTE6LHHHtPo0aPl7++vzp07F9un8kKwBwAAAIDryODBg7V06VLb6yVLlujBBx+0q3n66ae1dOlSzZ8/X/v379cTTzyhBx54QJs2bZIkHT16VPfcc4969OihpKQkPfTQQ5owYUK59Lds2TL5+/trx44dGjlypB555BHde++9ateunXbv3q2uXbsqNjZW2dnZl5ynSpUqevzxx/XLL78oMTFRknTmzBn16NFD69ev1549e9S1a1fdeeedSklJsVv31VdfVatWrbRnzx6NGDFCjzzyiA4ePChJOn36tO688041btxYu3fv1vPPP6/x48fbrZ+amqr27durWbNm2rVrlxISEnT8+HH17du32L46Oztr8+bNWrBgwdW+dRd/LypsZgAAAADANRcbG6tvv/1WR44c0S+//KLNmzfrgQcesC0/e/asZs2apSVLlqhr166qXbu2Bg0apAceeMAWPufPn6/atWtr9uzZioyM1IABAzRo0KBy6a9p06Z6+umnFRERoYkTJ8rDw0P+/v4aOnSoIiIi9Oyzz+r333/X3r17LztX/fr1Jcl2NUHTpk01fPhwNW7cWBEREZo2bZpq166tjz76yG69Hj16aMSIEapbt67Gjx8vf39/bdy4UZK0cuVKWSwWLVq0SA0bNlT37t315JNP2q0/f/58tWjRQtOnT1f9+vXVvHlzLVmyRBs2bNAPP/xgq6tbt65mzpypyMhIW68VgXvsAQAAAOA64u/vr549e2rZsmUyDEM9e/aUv///ngtw4MAB5ebmFrs0PD8/33a5fnJystq2bSuLxWJbHh0dXS79NWnSxPZnJycn+fn5qXHjxraxwMBASdKJEycuO5dhGJJk6/Ps2bOaOnWqPvnkE/322286d+6ccnJyip2x/2sPFotFQUFBtu0dOnRITZo0kbu7u62mTZs2dusnJiZqw4YNqlq1arGe/vvf/6pevXqSpFatWl12H8oDwR4AAAAArjMPPvigHnvsMUnSG2+8YbesqKhIkvTpp5/qpptuslvm5uYm6X+BuTSqVKlSbL2CgoJidS4uLnavLRaL3dj5kH6+z0tJTk6WJNtT85988kn95z//0SuvvKK6devKw8ND//jHP5Sfn3/ZHs5vzzAMu19onB/7q6KiIt1555166aWXivUUHBxs+7OXl9dl96E8EOwBAAAA4DrTrVs3W5jt2rWr3bKGDRvKzc1NKSkpat++fYnrN2zYUGvXrrUb27Zt2yW3WaNGDe3bt89uLCkpqViILi9FRUV6/fXXFR4ebrvS4JtvvtGgQYN09913S/rznvsLH/p3OfXr19fKlSuVl5dn+0XHrl277GpatGihDz74QLVq1ZKzs+NjteM7AAAAAACTyDyaaYptODk52c5mOzk52S3z9vbW2LFj9cQTT6ioqEh/+9vflJWVpS1btqhq1aoaOHCgHn74Yb366qsaPXq0hg8frsTERMXHx19ym3fccYdefvllvfPOO4qOjtaKFSu0b98+u6fxX43ff/9daWlpys7O1r59+zRnzhzt2LFDn376qW0f69atqw8//FB33nmnLBaLnnnmmSs68/9X/fv316RJkzRs2DBNmDBBKSkpeuWVVyT972qCRx99VIsWLdL999+vJ598Uv7+/vrpp5+0evVqLVq0qNh7XtEI9gAAAABwGf7+/vLw9NDXM7++Jtvz8PSwuy++LHx8fC667Pnnn1dAQIBmzJihn3/+WdWqVVOLFi301FNPSZLCwsL0wQcf6IknntCbb76pNm3a2L4i7mK6du2qZ555RuPGjVNubq4efPBB/fOf/9T3339/VftxXqdOnSRJnp6eqlmzpjp06KCFCxeqbt26tprZs2frwQcfVLt27eTv76/x48crKyurVNvx8fHRxx9/rEceeUTNmjVT48aN9eyzz6p///62++5DQkK0efNmjR8/Xl27dlVeXp5q1qypbt26qUqVa/+MeotRlpsnbkBZWVmyWq3KzMy85D8QR9u9e7datmypzpOWyjcs0tHt2PyRckjrXhisxMREtWjRwtHtAAAAACXKzc3V4cOHFR4ebvfwNElKSUmx+57yiuTv76+wsLBrsi1c3sqVKzV48GBlZmbKw8OjXOe+1DF3pTmUM/YAAAAAcAXCwsII2zeId955R7Vr19ZNN92k7777TuPHj1ffvn3LPdSXF4I9AAAAAAB/kZaWpmeffVZpaWkKDg7WvffeqxdeeMHRbV0UwR4AAAAAgL8YN26cxo0b5+g2rti1v6sfAAAAAACUG4I9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABPjqfgAAAAAcAVSUlKUnp5+Tbbl7++vsLCwa7ItmB/BHgAAAAAuIyUlRQ3q11d2Ts412Z6nh4eSDx687sP9xo0b1aFDB2VkZKhatWqObse0CPYAAAAAcBnp6enKzsnRnFv/prpWa4Vu66fMTMVt/lbp6emlCvaDBg3SsmXLNGPGDE2YMME2vnbtWt19990yDKMi2kUlQLAHAAAAgCtU12pVIz8/R7dxUe7u7nrppZc0fPhwVa9evVzmzM/Pl6ura7nMhYrBw/MAAAAA4DrRqVMnBQUFacaMGRet+eCDD3TLLbfIzc1NtWrV0quvvmq3vFatWpo2bZoGDRokq9WqoUOHKj4+XtWqVdMnn3yiyMhIeXp66h//+IfOnj2rZcuWqVatWqpevbpGjhypwsJC21wrVqxQq1at5O3traCgIPXv318nTpyosP2/URHsAQAAAOA64eTkpOnTp2vu3Lk6duxYseWJiYnq27ev+vXrp++//15TpkzRM888o/j4eLu6l19+WY0aNVJiYqKeeeYZSVJ2drZef/11rV69WgkJCdq4caPuueceffbZZ/rss8+0fPlyLVy4UO+//75tnvz8fD3//PP67rvvtHbtWh0+fFiDBg2qyLfghsSl+AAAAABwHbn77rvVrFkzTZ48WYsXL7ZbNmvWLHXs2NEW1uvVq6cDBw7o5Zdftgvcd9xxh8aOHWt7/e2336qgoEDz589XnTp1JEn/+Mc/tHz5ch0/flxVq1ZVw4YN1aFDB23YsEH33XefJOnBBx+0zVG7dm29/vrratOmjc6cOaOqVatW1Ftww+GMPQAAAABcZ1566SUtW7ZMBw4csBtPTk7Wrbfeajd266236scff7S7hL5Vq1bF5vT09LSFekkKDAxUrVq17AJ6YGCg3aX2e/bs0V133aWaNWvK29tbMTExkv78lgGUH4I9AAAAAFxnbr/9dnXt2lVPPfWU3bhhGLJYLMXGLuTl5VVszMXFxe61xWIpcayoqEiSdPbsWXXp0kVVq1bVihUrtHPnTq1Zs0bSn5foo/xwKT4AAAAAXIdefPFFNWvWTPXq1bONNWzYUN9++61d3ZYtW1SvXj05OTmV6/YPHjyo9PR0vfjiiwoNDZUk7dq1q1y3gT8R7AEAAADgCv2UmWmabTRu3FgDBgzQ3LlzbWNjxoxR69at9fzzz+u+++7T1q1bNW/ePL355pvlss2/CgsLk6urq+bOnauHH35Y+/bt0/PPP1/u2wHBHgAAAAAuy9/fX54eHorb/O3li8uBp4eH/P39r3qe559/Xv/6179sr1u0aKF//etfevbZZ/X8888rODhYzz33XIU8qb5GjRqKj4/XU089pddff10tWrTQK6+8ot69e5f7tm50FqOkGypQTFZWlqxWqzIzM+Xj4+Podi5q9+7datmypTpPWirfsEhHt2PzR8ohrXthsBITE9WiRQtHtwMAAACUKDc3V4cPH1Z4eLjc3d3tlqWkpCg9Pf2a9OHv76+wsLBrsi041qWOuSvNoZyxBwAAAIArEBYWRthGpcRT8QEAAAAAMDGCPQAAAAAAJkawBwAAAADAxAj2AAAAAHABnjGOa6U8jjWCPQAAAAD8fy4uLpKk7OxsB3eCG8X5Y+38sVcWPBUfAAAAAP4/JycnVatWTSdOnJAkeXp6ymKxOLgrXI8Mw1B2drZOnDihatWqycnJqcxzEewBAAAA4C+CgoIkyRbugYpUrVo12zFXVgR7AAAAAPgLi8Wi4OBgBQQEqKCgwNHt4Drm4uJyVWfqzyPYAwAAAEAJnJycyiV0ARWNh+cBAAAAAGBiBHsAAAAAAEyMYA8AAAAAgIkR7AEAAAAAMDGCPQAAAAAAJkawBwAAAADAxAj2AAAAAACYGMEeAAAAAAATI9gDAAAAAGBiBHsAAAAAAEyMYA8AAAAAgIkR7AEAAAAAMDGCPQAAAAAAJubwYP/rr7/qgQcekJ+fnzw9PdWsWTMlJibalhuGoSlTpigkJEQeHh6KiYnR/v377ebIy8vTyJEj5e/vLy8vL/Xu3VvHjh2zq8nIyFBsbKysVqusVqtiY2N16tSpa7GLAAAAAABUGIcG+4yMDN16661ycXHR559/rgMHDujVV19VtWrVbDUzZ87UrFmzNG/ePO3cuVNBQUHq3LmzTp8+bauJi4vTmjVrtHr1an377bc6c+aMevXqpcLCQltN//79lZSUpISEBCUkJCgpKUmxsbHXcncBAAAAACh3zo7c+EsvvaTQ0FAtXbrUNlarVi3bnw3D0Jw5czRp0iTdc889kqRly5YpMDBQq1at0vDhw5WZmanFixdr+fLl6tSpkyRpxYoVCg0N1fr169W1a1clJycrISFB27ZtU1RUlCRp0aJFio6O1qFDhxQZGXntdhoAAAAAgHLk0DP2H330kVq1aqV7771XAQEBat68uRYtWmRbfvjwYaWlpalLly62MTc3N7Vv315btmyRJCUmJqqgoMCuJiQkRI0aNbLVbN26VVar1RbqJalt27ayWq22mgvl5eUpKyvL7gcAAAAAgMrGocH+559/1vz58xUREaH//Oc/evjhhzVq1Ci98847kqS0tDRJUmBgoN16gYGBtmVpaWlydXVV9erVL1kTEBBQbPsBAQG2mgvNmDHDdj++1WpVaGjo1e0sAAAAAAAVwKHBvqioSC1atND06dPVvHlzDR8+XEOHDtX8+fPt6iwWi91rwzCKjV3owpqS6i81z8SJE5WZmWn7OXr06JXuFgAAAAAA14xDg31wcLAaNmxoN9agQQOlpKRIkoKCgiSp2Fn1EydO2M7iBwUFKT8/XxkZGZesOX78eLHtnzx5stjVAOe5ubnJx8fH7gcAAAAAgMrGocH+1ltv1aFDh+zGfvjhB9WsWVOSFB4erqCgIK1bt862PD8/X5s2bVK7du0kSS1btpSLi4tdTWpqqvbt22eriY6OVmZmpnbs2GGr2b59uzIzM201AAAAAACYkUOfiv/EE0+oXbt2mj59uvr27asdO3Zo4cKFWrhwoaQ/L5+Pi4vT9OnTFRERoYiICE2fPl2enp7q37+/JMlqtWrIkCEaM2aM/Pz85Ovrq7Fjx6px48a2p+Q3aNBA3bp109ChQ7VgwQJJ0rBhw9SrVy+eiA8AAAAAMDWHBvvWrVtrzZo1mjhxop577jmFh4drzpw5GjBggK1m3LhxysnJ0YgRI5SRkaGoqCh98cUX8vb2ttXMnj1bzs7O6tu3r3JyctSxY0fFx8fLycnJVrNy5UqNGjXK9vT83r17a968edduZwEAAACgkkpJSVF6erqj27im/P39FRYW5ug2yoXFMAzD0U2YQVZWlqxWqzIzMyv1/fa7d+9Wy5Yt1XnSUvmGVZ6rEf5IOaR1LwxWYmKiWrRo4eh2AAAAAPx/KSkpalC/vrJzchzdyjXl6eGh5IMHK3W4v9Ic6tAz9gAAAAAAx0pPT1d2To7m3Po31bVaHd3ONfFTZqbiNn+r9PT0Sh3srxTBHgAAAACgularGvn5OboNlIFDn4oPAAAAAACuDsEeAAAAAAATI9gDAAAAAGBiBHsAAAAAAEyMYA8AAAAAgIkR7AEAAAAAMDGCPQAAAAAAJkawBwAAAADAxAj2AAAAAACYGMEeAAAAAAATI9gDAAAAAGBiBHsAAAAAAEyMYA8AAAAAgIkR7AEAAAAAMDFnRzeAipGVesTRLdg5309ycrL8/f0VFhbm2IYAAAAA4DpBsL/OpKamShZp+5Kpjm6lRA888IA8PD10MPkg4R4AAAAAygHB/jpz6tQpyZBqDWoir5p+jm7HpjAvT5mphxVqDdWO13coPT2dYA8AAAAA5YBgf51yD6oqr5rVHd2GzbncHOUabvL29XZ0KwAAAABwXeHheQAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJOTTYT5kyRRaLxe4nKCjIttwwDE2ZMkUhISHy8PBQTEyM9u/fbzdHXl6eRo4cKX9/f3l5eal37946duyYXU1GRoZiY2NltVpltVoVGxurU6dOXYtdBAAAAACgQjn8jP0tt9yi1NRU28/3339vWzZz5kzNmjVL8+bN086dOxUUFKTOnTvr9OnTtpq4uDitWbNGq1ev1rfffqszZ86oV69eKiwstNX0799fSUlJSkhIUEJCgpKSkhQbG3tN9xMAAAAAgIrg7PAGnJ3tztKfZxiG5syZo0mTJumee+6RJC1btkyBgYFatWqVhg8frszMTC1evFjLly9Xp06dJEkrVqxQaGio1q9fr65duyo5OVkJCQnatm2boqKiJEmLFi1SdHS0Dh06pMjIyGu3swAAAAAAlDOHn7H/8ccfFRISovDwcPXr108///yzJOnw4cNKS0tTly5dbLVubm5q3769tmzZIklKTExUQUGBXU1ISIgaNWpkq9m6dausVqst1EtS27ZtZbVabTUlycvLU1ZWlt0PAAAAAACVjUODfVRUlN555x395z//0aJFi5SWlqZ27drp999/V1pamiQpMDDQbp3AwEDbsrS0NLm6uqp69eqXrAkICCi27YCAAFtNSWbMmGG7J99qtSo0NPSq9hUAAAAAgIrg0GDfvXt3/f3vf1fjxo3VqVMnffrpp5L+vOT+PIvFYreOYRjFxi50YU1J9ZebZ+LEicrMzLT9HD169Ir2CQAAAACAa8nhl+L/lZeXlxo3bqwff/zRdt/9hWfVT5w4YTuLHxQUpPz8fGVkZFyy5vjx48W2dfLkyWJXA/yVm5ubfHx87H4AAAAAAKhsKlWwz8vLU3JysoKDgxUeHq6goCCtW7fOtjw/P1+bNm1Su3btJEktW7aUi4uLXU1qaqr27dtnq4mOjlZmZqZ27Nhhq9m+fbsyMzNtNQAAAAAAmJVDn4o/duxY3XnnnQoLC9OJEyc0bdo0ZWVlaeDAgbJYLIqLi9P06dMVERGhiIgITZ8+XZ6enurfv78kyWq1asiQIRozZoz8/Pzk6+ursWPH2i7tl6QGDRqoW7duGjp0qBYsWCBJGjZsmHr16sUT8QEAAAAApufQYH/s2DHdf//9Sk9PV40aNdS2bVtt27ZNNWvWlCSNGzdOOTk5GjFihDIyMhQVFaUvvvhC3t7etjlmz54tZ2dn9e3bVzk5OerYsaPi4+Pl5ORkq1m5cqVGjRple3p+7969NW/evGu7swAAAAAAVACHBvvVq1dfcrnFYtGUKVM0ZcqUi9a4u7tr7ty5mjt37kVrfH19tWLFirK2CQAAAABApVWp7rEHAAAAAAClQ7AHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwsUoT7GfMmCGLxaK4uDjbmGEYmjJlikJCQuTh4aGYmBjt37/fbr28vDyNHDlS/v7+8vLyUu/evXXs2DG7moyMDMXGxspqtcpqtSo2NlanTp26BnsFAAAAAEDFqhTBfufOnVq4cKGaNGliNz5z5kzNmjVL8+bN086dOxUUFKTOnTvr9OnTtpq4uDitWbNGq1ev1rfffqszZ86oV69eKiwstNX0799fSUlJSkhIUEJCgpKSkhQbG3vN9g8AAAAAgIri8GB/5swZDRgwQIsWLVL16tVt44ZhaM6cOZo0aZLuueceNWrUSMuWLVN2drZWrVolScrMzNTixYv16quvqlOnTmrevLlWrFih77//XuvXr5ckJScnKyEhQW+//baio6MVHR2tRYsW6ZNPPtGhQ4ccss8AAAAAAJQXhwf7Rx99VD179lSnTp3sxg8fPqy0tDR16dLFNubm5qb27dtry5YtkqTExEQVFBTY1YSEhKhRo0a2mq1bt8pqtSoqKspW07ZtW1mtVltNSfLy8pSVlWX3AwAAAABAZePsyI2vXr1au3fv1s6dO4stS0tLkyQFBgbajQcGBuqXX36x1bi6utqd6T9fc379tLQ0BQQEFJs/ICDAVlOSGTNmaOrUqaXbIQAAAAAArjGHnbE/evSoHn/8ca1YsULu7u4XrbNYLHavDcMoNnahC2tKqr/cPBMnTlRmZqbt5+jRo5fcJgAAAAAAjuCwYJ+YmKgTJ06oZcuWcnZ2lrOzszZt2qTXX39dzs7OtjP1F55VP3HihG1ZUFCQ8vPzlZGRccma48ePF9v+yZMni10N8Fdubm7y8fGx+wEAAAAAoLJxWLDv2LGjvv/+eyUlJdl+WrVqpQEDBigpKUm1a9dWUFCQ1q1bZ1snPz9fmzZtUrt27SRJLVu2lIuLi11Namqq9u3bZ6uJjo5WZmamduzYYavZvn27MjMzbTUAAAAAAJiVw+6x9/b2VqNGjezGvLy85OfnZxuPi4vT9OnTFRERoYiICE2fPl2enp7q37+/JMlqtWrIkCEaM2aM/Pz85Ovrq7Fjx6px48a2h/E1aNBA3bp109ChQ7VgwQJJ0rBhw9SrVy9FRkZewz0GAAAAAKD8OfTheZczbtw45eTkaMSIEcrIyFBUVJS++OILeXt722pmz54tZ2dn9e3bVzk5OerYsaPi4+Pl5ORkq1m5cqVGjRple3p+7969NW/evGu+PwAAAAAAlLdKFew3btxo99pisWjKlCmaMmXKRddxd3fX3LlzNXfu3IvW+Pr6asWKFeXUJQAAAAAAlYfDv8ceAAAAAACUXZmCfe3atfX7778XGz916pRq16591U0BAAAAAIArU6Zgf+TIERUWFhYbz8vL06+//nrVTQEAAAAAgCtTqnvsP/roI9uf//Of/8hqtdpeFxYW6ssvv1StWrXKrTkAAAAAAHBppQr2ffr0kfTnQ+0GDhxot8zFxUW1atXSq6++Wm7NAQAAAACASytVsC8qKpIkhYeHa+fOnfL396+QpgAAAAAAwJUp09fdHT58uLz7AAAAAAAAZVDm77H/8ssv9eWXX+rEiRO2M/nnLVmy5KobAwAAAAAAl1emYD916lQ999xzatWqlYKDg2WxWMq7LwAAAAAAcAXKFOzfeustxcfHKzY2trz7AQAAAAAApVCm77HPz89Xu3btyrsXAAAAAABQSmUK9g899JBWrVpV3r0AAAAAAIBSKtOl+Lm5uVq4cKHWr1+vJk2ayMXFxW75rFmzyqU5AAAAAABwaWUK9nv37lWzZs0kSfv27bNbxoP0AAAAAAC4dsoU7Dds2FDefQAAAAAAgDIo0z32AAAAAACgcijTGfsOHTpc8pL7r776qswNAQAAAACAK1emYH/+/vrzCgoKlJSUpH379mngwIHl0RcAAAAAALgCZQr2s2fPLnF8ypQpOnPmzFU1BAAAAAAArly53mP/wAMPaMmSJeU5JQAAAAAAuIRyDfZbt26Vu7t7eU4JAAAAAAAuoUyX4t9zzz12rw3DUGpqqnbt2qVnnnmmXBoDAAAAAACXV6Zgb7Va7V5XqVJFkZGReu6559SlS5dyaQwAAAAAAFxemYL90qVLy7sPAAAAAABQBmUK9uclJiYqOTlZFotFDRs2VPPmzcurLwAAAAAAcAXKFOxPnDihfv36aePGjapWrZoMw1BmZqY6dOig1atXq0aNGuXdJwAAAAAAKEGZnoo/cuRIZWVlaf/+/frjjz+UkZGhffv2KSsrS6NGjSrvHgEAAAAAwEWU6Yx9QkKC1q9frwYNGtjGGjZsqDfeeIOH5wEAAAAAcA2V6Yx9UVGRXFxcio27uLioqKjoqpsCAAAAAABXpkzB/o477tDjjz+u3377zTb266+/6oknnlDHjh3LrTkAAAAAAHBpZQr28+bN0+nTp1WrVi3VqVNHdevWVXh4uE6fPq25c+eWd48AAAAAAOAiynSPfWhoqHbv3q1169bp4MGDMgxDDRs2VKdOncq7PwAAAAAAcAmlOmP/1VdfqWHDhsrKypIkde7cWSNHjtSoUaPUunVr3XLLLfrmm28qpFEAAAAAAFBcqYL9nDlzNHToUPn4+BRbZrVaNXz4cM2aNavcmgMAAAAAAJdWqmD/3XffqVu3bhdd3qVLFyUmJl51UwAAAAAA4MqUKtgfP368xK+5O8/Z2VknT5686qYAAAAAAMCVKVWwv+mmm/T9999fdPnevXsVHBx81U0BAAAAAIArU6pg36NHDz377LPKzc0ttiwnJ0eTJ09Wr169yq05AAAAAABwaaX6urunn35aH374oerVq6fHHntMkZGRslgsSk5O1htvvKHCwkJNmjSponoFAAAAAAAXKFWwDwwM1JYtW/TII49o4sSJMgxDkmSxWNS1a1e9+eabCgwMrJBGAQAAAABAcaUK9pJUs2ZNffbZZ8rIyNBPP/0kwzAUERGh6tWrV0R/AAAAAADgEkod7M+rXr26WrduXZ69AAAAAACAUirVw/MAAAAAAEDlQrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiTk02M+fP19NmjSRj4+PfHx8FB0drc8//9y23DAMTZkyRSEhIfLw8FBMTIz2799vN0deXp5Gjhwpf39/eXl5qXfv3jp27JhdTUZGhmJjY2W1WmW1WhUbG6tTp05di10EAAAAAKBCOTTY33zzzXrxxRe1a9cu7dq1S3fccYfuuusuW3ifOXOmZs2apXnz5mnnzp0KCgpS586ddfr0adsccXFxWrNmjVavXq1vv/1WZ86cUa9evVRYWGir6d+/v5KSkpSQkKCEhAQlJSUpNjb2mu8vAAAAAADlzdmRG7/zzjvtXr/wwguaP3++tm3bpoYNG2rOnDmaNGmS7rnnHknSsmXLFBgYqFWrVmn48OHKzMzU4sWLtXz5cnXq1EmStGLFCoWGhmr9+vXq2rWrkpOTlZCQoG3btikqKkqStGjRIkVHR+vQoUOKjIwssbe8vDzl5eXZXmdlZVXEWwAAAAAAwFWpNPfYFxYWavXq1Tp79qyio6N1+PBhpaWlqUuXLrYaNzc3tW/fXlu2bJEkJSYmqqCgwK4mJCREjRo1stVs3bpVVqvVFuolqW3btrJarbaaksyYMcN26b7ValVoaGh57zIAAAAAAFfN4cH++++/V9WqVeXm5qaHH35Ya9asUcOGDZWWliZJCgwMtKsPDAy0LUtLS5Orq6uqV69+yZqAgIBi2w0ICLDVlGTixInKzMy0/Rw9evSq9hMAAAAAgIrg0EvxJSkyMlJJSUk6deqUPvjgAw0cOFCbNm2yLbdYLHb1hmEUG7vQhTUl1V9uHjc3N7m5uV3pbgAAAAAA4BAOP2Pv6uqqunXrqlWrVpoxY4aaNm2q1157TUFBQZJU7Kz6iRMnbGfxg4KClJ+fr4yMjEvWHD9+vNh2T548WexqAAAAAAAAzMbhwf5ChmEoLy9P4eHhCgoK0rp162zL8vPztWnTJrVr106S1LJlS7m4uNjVpKamat++fbaa6OhoZWZmaseOHbaa7du3KzMz01YDAAAAAIBZOfRS/Keeekrdu3dXaGioTp8+rdWrV2vjxo1KSEiQxWJRXFycpk+froiICEVERGj69Ony9PRU//79JUlWq1VDhgzRmDFj5OfnJ19fX40dO1aNGze2PSW/QYMG6tatm4YOHaoFCxZIkoYNG6ZevXpd9In4AAAAAACYhUOD/fHjxxUbG6vU1FRZrVY1adJECQkJ6ty5syRp3LhxysnJ0YgRI5SRkaGoqCh98cUX8vb2ts0xe/ZsOTs7q2/fvsrJyVHHjh0VHx8vJycnW83KlSs1atQo29Pze/furXnz5l3bnQUAAAAAoAI4NNgvXrz4ksstFoumTJmiKVOmXLTG3d1dc+fO1dy5cy9a4+vrqxUrVpS1TQAAAAAAKq1Kd489AAAAAAC4cgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAE3NosJ8xY4Zat24tb29vBQQEqE+fPjp06JBdjWEYmjJlikJCQuTh4aGYmBjt37/friYvL08jR46Uv7+/vLy81Lt3bx07dsyuJiMjQ7GxsbJarbJarYqNjdWpU6cqehcd5lxBvs7l5lSen/xcSVJu7p//m5ycrN27dyslJcWRbxMAAAAAmJ6zIze+adMmPfroo2rdurXOnTunSZMmqUuXLjpw4IC8vLwkSTNnztSsWbMUHx+vevXqadq0aercubMOHTokb29vSVJcXJw+/vhjrV69Wn5+fhozZox69eqlxMREOTk5SZL69++vY8eOKSEhQZI0bNgwxcbG6uOPP3bMzleQ9PR0SdLZ9F91zjndwd0U9/PPP0uSHnjgAUmSp4e7kg8eUlhYmCPbAgAAAADTcmiwPx+yz1u6dKkCAgKUmJio22+/XYZhaM6cOZo0aZLuueceSdKyZcsUGBioVatWafjw4crMzNTixYu1fPlyderUSZK0YsUKhYaGav369eratauSk5OVkJCgbdu2KSoqSpK0aNEiRUdH69ChQ4qMjLy2O16BTp8+LUm6uZqbAm7ydnA3/2MUFaowP1f58lKqpBXDmkmSHliYpPT0dII9AAAAAJSRQ4P9hTIzMyVJvr6+kqTDhw8rLS1NXbp0sdW4ubmpffv22rJli4YPH67ExEQVFBTY1YSEhKhRo0basmWLunbtqq1bt8pqtdpCvSS1bdtWVqtVW7ZsKTHY5+XlKS8vz/Y6Kyur3Pe3Irk6W+Tl5uToNmyMIqnAsMjZ9c+7PxoEV3VwRwAAAABwfag0D88zDEOjR4/W3/72NzVq1EiSlJaWJkkKDAy0qw0MDLQtS0tLk6urq6pXr37JmoCAgGLbDAgIsNVcaMaMGbb78a1Wq0JDQ69uBwEAAAAAqACVJtg/9thj2rt3r959991iyywWi91rwzCKjV3owpqS6i81z8SJE5WZmWn7OXr06JXsBgAAAAAA11SlCPYjR47URx99pA0bNujmm2+2jQcFBUlSsbPqJ06csJ3FDwoKUn5+vjIyMi5Zc/z48WLbPXnyZLGrAc5zc3OTj4+P3Q8AAAAAAJWNQ4O9YRh67LHH9OGHH+qrr75SeHi43fLw8HAFBQVp3bp1trH8/Hxt2rRJ7dq1kyS1bNlSLi4udjWpqanat2+frSY6OlqZmZnasWOHrWb79u3KzMy01QAAAAAAYEYOfXjeo48+qlWrVun//u//5O3tbTszb7Va5eHhIYvFori4OE2fPl0RERGKiIjQ9OnT5enpqf79+9tqhwwZojFjxsjPz0++vr4aO3asGjdubHtKfoMGDdStWzcNHTpUCxYskPTn19316tXrunoiPgAAAADgxuPQYD9//nxJUkxMjN340qVLNWjQIEnSuHHjlJOToxEjRigjI0NRUVH64osvbN9hL0mzZ8+Ws7Oz+vbtq5ycHHXs2FHx8fG277CXpJUrV2rUqFG2p+f37t1b8+bNq9gdBAAAAACggjk02BuGcdkai8WiKVOmaMqUKRetcXd319y5czV37tyL1vj6+mrFihVlaRMAAAAAgEqrUjw8DwAAAAAAlA3BHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMScHd0AAAAArq2UlBSlp6c7uo1L8vf3V1hYmKPbAABTINgDAADcQFJSUlS/QX3lZOc4upVL8vD00MHkg4R7ALgCBHsAAIAbSHp6unKyc3T7uNtlDbU6up0SZR7N1Nczv1Z6ejrBHgCuAMEeAADgBmQNtco/wt/RbQAAygEPzwMAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACbm7OgGAAAA4Di5ubkqKChwdBt2srOzHd0CAJgKwR4AAOAGlZubqx3bd6iwqNDRrdjJS8uTJKWmpjq4EwAwB4I9AADADaqgoECFRYXyCQ6Xs6u7o9uxyTp3UlKqTp065ehWAMAUCPYAAAA3OGdXdzm7ezi6DRtnF1dHtwAApsLD8wAAAAAAMDGCPQAAAAAAJkawBwAAAADAxAj2AAAAAACYGMEeAAAAAAATI9gDAAAAAGBiBHsAAAAAAEyMYA8AAAAAgIk5NNh//fXXuvPOOxUSEiKLxaK1a9faLTcMQ1OmTFFISIg8PDwUExOj/fv329Xk5eVp5MiR8vf3l5eXl3r37q1jx47Z1WRkZCg2NlZWq1VWq1WxsbE6depUBe8dAAAAAAAVz6HB/uzZs2ratKnmzZtX4vKZM2dq1qxZmjdvnnbu3KmgoCB17txZp0+fttXExcVpzZo1Wr16tb799ludOXNGvXr1UmFhoa2mf//+SkpKUkJCghISEpSUlKTY2NgK3z8AAAAAACqasyM33r17d3Xv3r3EZYZhaM6cOZo0aZLuueceSdKyZcsUGBioVatWafjw4crMzNTixYu1fPlyderUSZK0YsUKhYaGav369eratauSk5OVkJCgbdu2KSoqSpK0aNEiRUdH69ChQ4qMjLw2OwsAAAAAQAWotPfYHz58WGlpaerSpYttzM3NTe3bt9eWLVskSYmJiSooKLCrCQkJUaNGjWw1W7duldVqtYV6SWrbtq2sVqutpiR5eXnKysqy+wEAAAAAoLKptME+LS1NkhQYGGg3HhgYaFuWlpYmV1dXVa9e/ZI1AQEBxeYPCAiw1ZRkxowZtnvyrVarQkNDr2p/AAAAAACoCJU22J9nsVjsXhuGUWzsQhfWlFR/uXkmTpyozMxM28/Ro0dL2TkAAAAAABWv0gb7oKAgSSp2Vv3EiRO2s/hBQUHKz89XRkbGJWuOHz9ebP6TJ08Wuxrgr9zc3OTj42P3AwAAAABAZVNpg314eLiCgoK0bt0621h+fr42bdqkdu3aSZJatmwpFxcXu5rU1FTt27fPVhMdHa3MzEzt2LHDVrN9+3ZlZmbaagAAAAAAMCuHPhX/zJkz+umnn2yvDx8+rKSkJPn6+iosLExxcXGaPn26IiIiFBERoenTp8vT01P9+/eXJFmtVg0ZMkRjxoyRn5+ffH19NXbsWDVu3Nj2lPwGDRqoW7duGjp0qBYsWCBJGjZsmHr16sUT8QEAAAAApufQYL9r1y516NDB9nr06NGSpIEDByo+Pl7jxo1TTk6ORowYoYyMDEVFRemLL76Qt7e3bZ3Zs2fL2dlZffv2VU5Ojjp27Kj4+Hg5OTnZalauXKlRo0bZnp7fu3dvzZs37xrtJQAAAAAAFcehwT4mJkaGYVx0ucVi0ZQpUzRlypSL1ri7u2vu3LmaO3fuRWt8fX21YsWKq2kVAAAAAIBKqdLeYw8AAAAAAC6PYA8AAAAAgIkR7AEAAAAAMDGCPQAAAAAAJkawBwAAAADAxAj2AAAAAACYGMEeAAAAAAATI9gDAAAAAGBiBHsAAAAAAEyMYA8AAAAAgIkR7AEAAAAAMDGCPQAAAAAAJkawBwAAAADAxAj2AAAAAACYGMEeAAAAAAATI9gDAAAAAGBiBHsAAAAAAEzM2dENAAAAoOKlpKQoPT1dycnJkqTs7GwVZhdKks7l5zqytWLOFeQ7ugUAMBWCPQAAwHUuJSVFDepHKjvnfwH+wIEDcvvDTZKUlXrYUa2VKC89T5KUnp7u4E4AwBwI9gAAANe59PR0ZefkasWwZpKkBxYmqWGIt3xudlP22bNycnWXpYqTY5v8ixO5Uqqk06dPO7oVADAFgj0AAMANokFwVdufPV2d5O3mJCPfIhc3p0oV7F2dLY5uAQBMhYfnAQAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAEyPYAwAAAABgYgR7AAAAAABMjGAPAAAAAICJEewBAAAAADAxgj0AAAAAACZGsAcAAAAAwMQI9gAAAAAAmBjBHgAAAAAAE3N2dAMAAPNJSUlRenq6o9u4KH9/f4WFhTm6DQAAgGuCYA8AKJWUlBTVb1BfOdk5jm7lojw8PXQw+SDhHgAA3BAI9gCAUklPT1dOdo5uH3e7rKFWR7dTTObRTH0982ulp6cT7AEAwA2BYA8AKBNrqFX+Ef6ObgMAAOCGx8PzAAAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIxgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrAHAAAAAMDEnB3dAADg2khJSVF6evpVz5OcnCxJys7O1unTp696PhcXF7m7u1/1PAAAADcqgj0A3ABSUlJUv34D5eRkl9ucBw4ckNsfblc9j1MVJ7WJakO4BwAAKCOCPQDcANLT05WTk62oByfLJ7jWVc2VlXpE25dMlTU4XJ5h1qua61x+rrJSD6ugoIBgDwAAUEYEewC4gfgE15JvWGS5zOXk5iZnd49ymQsAAABlx8PzAAAAAAAwMYI9AAAAAAAmRrAHAAAAAMDECPYAAAAAAJgYwR4AAAAAABMj2AMAAAAAYGIEewAAAAAATIzvsQeA61hKSorS09OVnJwsScpKPXLVc56fozAvT+dyc65qrnP5uZKk7OxsSZKLi4vc3d2vak4AAIAbDcEeAK5TKSkpalA/Utk5ubax7Uumltv8mamHlWu4lctcBw4ckCQ5VamiNlFRhHsAAIBSuKGC/ZtvvqmXX35ZqampuuWWWzRnzhzddtttjm4LACpEenq6snNytWJYM4VZLTpwIFk+wbXk7Hp1ofnnk9ma8O8fVCfAS9abPK5qLqOoUIX5ufL08lLeOenAb6dVUFBAsAcAACiFGybYv/fee4qLi9Obb76pW2+9VQsWLFD37t114MABhYWFObo9AKgwDYKrKsKvis4dr6LqwZ5ycfcsl3k9XKvIy83pquYwiqQCwyJvNyc58dQXAACAMrlhgv2sWbM0ZMgQPfTQQ5KkOXPm6D//+Y/mz5+vGTNmOLi78nfmeJ4y3LMd3YaNUVSkc3l5Opf15/9zT049Y1t2/t7fsvL39+eXMwAAAABuWDdEsM/Pz1diYqImTJhgN96lSxdt2bKlxHXy8vKUl5dne52ZmSlJysrKqrhGy8Hx48clSd+t+M3BnVzaAwuT/vfnBx64qrmcq1TRPf/4h7y9vUu9rsVikWEYVz1e3i63nSpVqqioqOiq5ijvnq5m25erv9Tysuzn1b43V7L+1W7jSv6OLyc9PV2SNCfhB/l5WpSenie3H4/I4uRydfOeKZAk/Xf77/L88Wo/Ew0VFZ6Ti2u2CgoNZWXm6/tfv5eLS9l7zE7/85eazz33nPz9/cs0R0X/HZf177es26zIfyflXXeltVfzuVGeLradi/0dX6u+LvTXzwNZ/hw7tO2kPA65qKAgX1Wczsi2oBI4nZ4vSTpy5Ii+/vprB3dTsvL4nDaTG21/pRtrnw8dOiRJ2vf778ouKHBwN9fGz/8/1505c6ZSZ7zzvV32v4uGI/7rco399ttvuummm7R582a1a9fONj59+nQtW7bMdiD/1ZQpUzR1avk9ZAoAAAAAgLI4evSobr755osuvyHO2J9nsdj/JtowjGJj502cOFGjR4+2vS4qKtIff/whPz+/i65TGWRlZSk0NFRHjx6Vj4+Po9uBCXDMoLQ4ZlBaHDMoLY4ZlBbHDErLLMeMYRg6ffq0QkJCLll3QwR7f39/OTk5KS0tzW78xIkTCgwMLHEdNzc3ubnZf41TtWrVKqrFcufj41OpD1BUPhwzKC2OGZQWxwxKi2MGpcUxg9IywzFjtVovW3NDPIPY1dVVLVu21Lp16+zG161bZ3dpPgAAAAAAZnNDnLGXpNGjRys2NlatWrVSdHS0Fi5cqJSUFD388MOObg0AAAAAgDK7YYL9fffdp99//13PPfecUlNT1ahRI3322WeqWbOmo1srV25ubpo8eXKx2wiAi+GYQWlxzKC0OGZQWhwzKC2OGZTW9XbM3BBPxQcAAAAA4Hp1Q9xjDwAAAADA9YpgDwAAAACAiRHsAQAAAAAwMYI9AAAAAAAmRrA3oTfffFPh4eFyd3dXy5Yt9c0331yyftOmTWrZsqXc3d1Vu3ZtvfXWW9eoU1QWpTlmNm7cKIvFUuzn4MGD17BjOMrXX3+tO++8UyEhIbJYLFq7du1l1+Ez5sZW2mOGzxjMmDFDrVu3lre3twICAtSnTx8dOnTosuvxWXPjKssxw2fNjW3+/Plq0qSJfHx85OPjo+joaH3++eeXXMfsnzEEe5N57733FBcXp0mTJmnPnj267bbb1L17d6WkpJRYf/jwYfXo0UO33Xab9uzZo6eeekqjRo3SBx98cI07h6OU9pg579ChQ0pNTbX9REREXKOO4Uhnz55V06ZNNW/evCuq5zMGpT1mzuMz5sa1adMmPfroo9q2bZvWrVunc+fOqUuXLjp79uxF1+Gz5sZWlmPmPD5rbkw333yzXnzxRe3atUu7du3SHXfcobvuukv79+8vsf66+IwxYCpt2rQxHn74Ybux+vXrGxMmTCixfty4cUb9+vXtxoYPH260bdu2wnpE5VLaY2bDhg2GJCMjI+MadIfKTJKxZs2aS9bwGYO/upJjhs8YXOjEiROGJGPTpk0XreGzBn91JccMnzW4UPXq1Y233367xGXXw2cMZ+xNJD8/X4mJierSpYvdeJcuXbRly5YS19m6dWux+q5du2rXrl0qKCiosF5ROZTlmDmvefPmCg4OVseOHbVhw4aKbBMmxmcMyorPGJyXmZkpSfL19b1oDZ81+KsrOWbO47MGhYWFWr16tc6ePavo6OgSa66HzxiCvYmkp6ersLBQgYGBduOBgYFKS0srcZ20tLQS68+dO6f09PQK6xWVQ1mOmeDgYC1cuFAffPCBPvzwQ0VGRqpjx476+uuvr0XLMBk+Y1BafMbgrwzD0OjRo/W3v/1NjRo1umgdnzU470qPGT5r8P3336tq1apyc3PTww8/rDVr1qhhw4Yl1l4PnzHOjm4ApWexWOxeG4ZRbOxy9SWN4/pVmmMmMjJSkZGRttfR0dE6evSoXnnlFd1+++0V2ifMic8YlAafMfirxx57THv37tW333572Vo+ayBd+THDZw0iIyOVlJSkU6dO6YMPPtDAgQO1adOmi4Z7s3/GcMbeRPz9/eXk5FTsTOuJEyeK/YbpvKCgoBLrnZ2d5efnV2G9onIoyzFTkrZt2+rHH38s7/ZwHeAzBuWBz5gb08iRI/XRRx9pw4YNuvnmmy9Zy2cNpNIdMyXhs+bG4urqqrp166pVq1aaMWOGmjZtqtdee63E2uvhM4ZgbyKurq5q2bKl1q1bZze+bt06tWvXrsR1oqOji9V/8cUXatWqlVxcXCqsV1QOZTlmSrJnzx4FBweXd3u4DvAZg/LAZ8yNxTAMPfbYY/rwww/11VdfKTw8/LLr8FlzYyvLMVMSPmtubIZhKC8vr8Rl18VnjIMe2ocyWr16teHi4mIsXrzYOHDggBEXF2d4eXkZR44cMQzDMCZMmGDExsba6n/++WfD09PTeOKJJ4wDBw4YixcvNlxcXIz333/fUbuAa6y0x8zs2bONNWvWGD/88IOxb98+Y8KECYYk44MPPnDULuAaOn36tLFnzx5jz549hiRj1qxZxp49e4xffvnFMAw+Y1BcaY8ZPmPwyCOPGFar1di4caORmppq+8nOzrbV8FmDvyrLMcNnzY1t4sSJxtdff20cPnzY2Lt3r/HUU08ZVapUMb744gvDMK7PzxiCvQm98cYbRs2aNQ1XV1ejRYsWdl/1MXDgQKN9+/Z29Rs3bjSaN29uuLq6GrVq1TLmz59/jTuGo5XmmHnppZeMOnXqGO7u7kb16tWNv/3tb8ann37qgK7hCOe/HujCn4EDBxqGwWcMiivtMcNnDEo6XiQZS5cutdXwWYO/Kssxw2fNje3BBx+0/X/fGjVqGB07drSFesO4Pj9jLIbx/58KAAAAAAAATId77AEAAAAAMDGCPQAAAAAAJkawBwAAAADAxAj2AAAAAACYGMEeAAAAAAATI9gDAAAAAGBiBHsAAAAAAEyMYA8AAAAAgIkR7AEAuIFMmTJFzZo1s70eNGiQ+vTpc837OHLkiCwWi5KSkipsGxfua1lciz4BALhaBHsAABxs0KBBslgsslgscnFxUe3atTV27FidPXu2wrf92muvKT4+/opqr3XIjYmJUVxc3DXZFgAAZubs6AYAAIDUrVs3LV26VAUFBfrmm2/00EMP6ezZs5o/f36x2oKCArm4uJTLdq1Wa7nMAwAAHIcz9gAAVAJubm4KCgpSaGio+vfvrwEDBmjt2rWS/ndJ+ZIlS1S7dm25ubnJMAxlZmZq2LBhCggIkI+Pj+644w599913dvO++OKLCgwMlLe3t4YMGaLc3Fy75Rdeil9UVKSXXnpJdevWlZubm8LCwvTCCy9IksLDwyVJzZs3l8ViUUxMjG29pUuXqkGDBnJ3d1f9+vX15ptv2m1nx44dat68udzd3dWqVSvt2bPnqt+z8ePHq169evL09FTt2rX1zDPPqKCgoFjdggULFBoaKk9PT9177706deqU3fLL9f5XGRkZGjBggGrUqCEPDw9FRERo6dKlV70vAABcDc7YAwBQCXl4eNiF1J9++kn/+te/9MEHH8jJyUmS1LNnT/n6+uqzzz6T1WrVggUL1LFjR/3www/y9fXVv/71L02ePFlvvPGGbrvtNi1fvlyvv/66ateufdHtTpw4UYsWLdLs2bP1t7/9TampqTp48KCkP8N5mzZttH79et1yyy1ydXWVJC1atEiTJ0/WvHnz1Lx5c+3Zs0dDhw6Vl5eXBg4cqLNnz6pXr1664447tGLFCh0+fFiPP/74Vb9H3t7eio+PV0hIiL7//nsNHTpU3t7eGjduXLH37eOPP1ZWVpaGDBmiRx99VCtXrryi3i/0zDPP6MCBA/r888/l7++vn376STk5OVe9LwAAXBUDAAA41MCBA4277rrL9nr79u2Gn5+f0bdvX8MwDGPy5MmGi4uLceLECVvNl19+afj4+Bi5ubl2c9WpU8dYsGCBYRiGER0dbTz88MN2y6OiooymTZuWuO2srCzDzc3NWLRoUYl9Hj582JBk7Nmzx248NDTUWLVqld3Y888/b0RHRxuGYRgLFiwwfH19jbNnz9qWz58/v8S5/qp9+/bG448/ftHlF5o5c6bRsmVL2+vJkycbTk5OxtGjR21jn3/+uVGlShUjNTX1inq/cJ/vvPNOY/DgwVfcEwAA1wJn7AEAqAQ++eQTVa1aVefOnVNBQYHuuusuzZ0717a8Zs2aqlGjhu11YmKizpw5Iz8/P7t5cnJy9N///leSlJycrIcffthueXR0tDZs2FBiD8nJycrLy1PHjh2vuO+TJ0/q6NGjGjJkiIYOHWobP3funO3+/eTkZDVt2lSenp52fVyt999/X3PmzNFPP/2kM2fO6Ny5c/Lx8bGrCQsL080332y33aKiIh06dEhOTk6X7f1CjzzyiP7+979r9+7d6tKli/r06aN27dpd9b4AAHA1CPYAAFQCHTp00Pz58+Xi4qKQkJBiD8fz8vKye11UVKTg4GBt3Lix2FzVqlUrUw8eHh6lXqeoqEjSn5e0R0VF2S07f8uAYRhl6udStm3bpn79+mnq1Knq2rWrrFarVq9erVdfffWS61ksFtv/XknvF+revbt++eUXffrpp1q/fr06duyoRx99VK+88ko57BUAAGVDsAcAoBLw8vJS3bp1r7i+RYsWSktLk7Ozs2rVqlViTYMGDbRt2zb985//tI1t27btonNGRETIw8NDX375pR566KFiy8/fU19YWGgbCwwM1E033aSff/5ZAwYMKHHehg0bavny5crJybH98uBSfVyJzZs3q2bNmpo0aZJt7JdffilWl5KSot9++00hISGSpK1bt6pKlSqqV6/eFfVekho1amjQoEEaNGiQbrvtNj355JMEewCAQxHsAQAwoU6dOik6Olp9+vTRSy+9pMjISP3222/67LPP1KdPH7Vq1UqPP/64Bg4cqFatWulvf/ubVq5cqf3791/04Xnu7u4aP368xo0bJ1dXV9166606efKk9u/fryFDhiggIEAeHh5KSEjQzTffLHd3d1mtVk2ZMkWjRo2Sj4+Punfvrry8PO3atUsZGRkaPfr/tXe/LpHEcRyH36KY7C7mRVj8gctiXZvBsmBwxSKoRRDBM4isO10wmRQMm2SbwR9/gtlkXo3abKa7duDdcWfxYOB5YMrADN9PfDEMn29ZW1tLp9PJ5uZmjo6OMhgMPh3Cr6+veXh4+HCvUqmkWq3m+fk5/X4/8/Pzub29zdXV1R9nWl9fz8nJSd7e3rK7u5uVlZVUKpUk+efZf1UURRqNRqampvL+/p6bm5vUarVPzQIAX8W6OwAooaGhodzd3aXZbGZjYyOTk5NZXV3NYDDI+Ph4kqTdbqcoihwcHKTRaOTp6Snb29t/fW+3283+/n6KokitVku73c7Ly0uSZGRkJKenpzk/P8/ExERarVaSZGtrKxcXF+n1epmZmcnCwkJ6vd7P9XhjY2O5vr7O4+Nj6vV6Op1Ojo+PPzXn5eVl6vX6h+vs7CytVit7e3vZ2dnJ3Nxc7u/v0+12f3u+Wq1meXk5S0tLWVxczPT09Id1dv86+69GR0dzeHiY2dnZNJvNDA8Pp9/vf2oWAPgqQ9+/4sc3AAAA4L/wxR4AAABKTNgDAABAiQl7AAAAKDFhDwAAACUm7AEAAKDEhD0AAACUmLAHAACAEhP2AAAAUGLCHgAAAEpM2AMAAECJCXsAAAAosR+MB1boXQrFNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "results_df = pd.DataFrame({'True Labels': true_labels, 'Predicted Labels': predicted_labels})\n",
    "\n",
    "# Create a bar plot for each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for class_label in class_labels:\n",
    "    subset_df = results_df[results_df['True Labels'] == class_labels.index(class_label)]\n",
    "    sns.histplot(subset_df['Predicted Labels'], label=class_label, stat=\"count\", common_norm=False, kde=False)\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title(\"Relationship Among Classes\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977eba85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have the classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=class_labels, output_dict=True)\n",
    "\n",
    "# Convert the classification report dictionary to a DataFrame\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plot precision, recall, and f1-score for each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Bar plot for precision\n",
    "sns.barplot(x=report_df.index, y=report_df['precision'], palette='viridis')\n",
    "plt.title('Precision for Each Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for recall\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=report_df.index, y=report_df['recall'], palette='viridis')\n",
    "plt.title('Recall for Each Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for f1-score\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=report_df.index, y=report_df['f1-score'], palette='viridis')\n",
    "plt.title('F1-Score for Each Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b3268",
   "metadata": {},
   "source": [
    "# TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1633cb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HighDanger', 'LowDanger', 'MediumDanger', 'Normal']\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 4)    256         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 4)            0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 4)            0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 229,472\n",
      "Trainable params: 228,288\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Found 71110 images belonging to 4 classes.\n",
      "Found 24551 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "4445/4445 [==============================] - 1546s 348ms/step - loss: 0.7597 - accuracy: 0.6691 - val_loss: 1.0561 - val_accuracy: 0.5030\n",
      "Epoch 2/20\n",
      "4445/4445 [==============================] - 220s 49ms/step - loss: 0.6789 - accuracy: 0.7101 - val_loss: 0.9335 - val_accuracy: 0.5848\n",
      "Epoch 3/20\n",
      "4445/4445 [==============================] - 223s 50ms/step - loss: 0.6419 - accuracy: 0.7340 - val_loss: 1.0849 - val_accuracy: 0.5332\n",
      "Epoch 4/20\n",
      "4445/4445 [==============================] - 224s 50ms/step - loss: 0.6069 - accuracy: 0.7562 - val_loss: 1.3331 - val_accuracy: 0.4981\n",
      "Epoch 5/20\n",
      "4445/4445 [==============================] - 229s 52ms/step - loss: 0.5729 - accuracy: 0.7792 - val_loss: 1.1988 - val_accuracy: 0.5623\n",
      "Epoch 6/20\n",
      "4445/4445 [==============================] - 231s 52ms/step - loss: 0.5469 - accuracy: 0.7949 - val_loss: 1.1803 - val_accuracy: 0.5788\n",
      "Epoch 7/20\n",
      "4445/4445 [==============================] - 233s 53ms/step - loss: 0.5215 - accuracy: 0.8107 - val_loss: 1.3618 - val_accuracy: 0.5264\n",
      "Epoch 8/20\n",
      "4445/4445 [==============================] - 235s 53ms/step - loss: 0.5054 - accuracy: 0.8207 - val_loss: 1.4496 - val_accuracy: 0.5749\n",
      "Epoch 9/20\n",
      "4445/4445 [==============================] - 235s 53ms/step - loss: 0.4876 - accuracy: 0.8328 - val_loss: 1.5181 - val_accuracy: 0.5944\n",
      "Epoch 10/20\n",
      "4445/4445 [==============================] - 236s 53ms/step - loss: 0.4740 - accuracy: 0.8408 - val_loss: 1.6635 - val_accuracy: 0.5051\n",
      "Epoch 11/20\n",
      "4445/4445 [==============================] - 238s 54ms/step - loss: 0.4654 - accuracy: 0.8473 - val_loss: 2.2702 - val_accuracy: 0.5492\n",
      "Epoch 12/20\n",
      "4445/4445 [==============================] - 242s 54ms/step - loss: 0.4530 - accuracy: 0.8529 - val_loss: 2.0026 - val_accuracy: 0.5846\n",
      "Epoch 13/20\n",
      "4445/4445 [==============================] - 238s 54ms/step - loss: 0.4492 - accuracy: 0.8572 - val_loss: 1.8255 - val_accuracy: 0.4901\n",
      "Epoch 14/20\n",
      "4445/4445 [==============================] - 238s 54ms/step - loss: 0.4422 - accuracy: 0.8604 - val_loss: 1.8232 - val_accuracy: 0.5581\n",
      "Epoch 15/20\n",
      "4445/4445 [==============================] - 241s 54ms/step - loss: 0.4375 - accuracy: 0.8641 - val_loss: 1.9968 - val_accuracy: 0.5350\n",
      "Epoch 16/20\n",
      "4445/4445 [==============================] - 238s 53ms/step - loss: 0.4324 - accuracy: 0.8674 - val_loss: 1.4836 - val_accuracy: 0.5785\n",
      "Epoch 17/20\n",
      "4445/4445 [==============================] - 243s 55ms/step - loss: 0.4216 - accuracy: 0.8744 - val_loss: 1.6920 - val_accuracy: 0.5594\n",
      "Epoch 18/20\n",
      "4445/4445 [==============================] - 239s 54ms/step - loss: 0.4188 - accuracy: 0.8756 - val_loss: 1.6877 - val_accuracy: 0.5461\n",
      "Epoch 19/20\n",
      "4445/4445 [==============================] - 238s 53ms/step - loss: 0.4163 - accuracy: 0.8773 - val_loss: 1.4961 - val_accuracy: 0.5969\n",
      "Epoch 20/20\n",
      "4445/4445 [==============================] - 239s 54ms/step - loss: 0.4091 - accuracy: 0.8806 - val_loss: 1.7063 - val_accuracy: 0.5422\n",
      "384/384 [==============================] - 28s 72ms/step - loss: 1.7063 - accuracy: 0.5422\n",
      "384/384 [==============================] - 28s 71ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  HighDanger       0.34      0.51      0.41      8408\n",
      "   LowDanger       0.11      0.17      0.13      2793\n",
      "MediumDanger       0.30      0.07      0.11      7413\n",
      "      Normal       0.24      0.23      0.23      5937\n",
      "\n",
      "    accuracy                           0.27     24551\n",
      "   macro avg       0.25      0.24      0.22     24551\n",
      "weighted avg       0.28      0.27      0.25     24551\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4283 1546  565 2014]\n",
      " [1465  471  171  686]\n",
      " [3747 1345  505 1816]\n",
      " [3062 1072  415 1388]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "class_labels = [\n",
    "    'HighDanger', 'LowDanger', 'MediumDanger', 'Normal'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\LEVEL_AHAR\\Train'\n",
    "validation1_data = r'D:\\LEVEL_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Calculate class weights\n",
    "# class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(training_set.classes), y=training_set.classes)\n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "# print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Model compilation with class weights\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with class weights\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set),\n",
    "#     class_weight=class_weight_dict  # Pass the calculated class weights\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "model.save('AHAR_equalvideos_savedmodel_epoch20_accuracy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1132bf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 154ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.3591871e-07 1.4838647e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.3352492e-07 2.0071250e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.5174227e-07 1.9472991e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.4936865e-07 1.8962743e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.3276966e-07 1.9360369e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.3791148e-07 2.5265036e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.5460914e-07 3.3579378e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.5960615e-07 3.5031233e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999988e-01 0.0000000e+00 1.6942967e-07 3.3316980e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 1.8554971e-07 4.5834576e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.0449320e-07 5.7062617e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[9.9999976e-01 0.0000000e+00 1.9909503e-07 8.8277875e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.2799813e-07 5.7966307e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.3796079e-07 5.7043359e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.2756109e-07 7.3388595e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.4411503e-07 7.6849727e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.6307126e-07 7.6076915e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.6247329e-07 6.8280288e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "[[9.9999976e-01 0.0000000e+00 2.9463706e-07 7.1895038e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999964e-01 0.0000000e+00 3.4397777e-07 9.9150539e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[9.9999964e-01 0.0000000e+00 3.9460491e-07 9.8659870e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[9.9999964e-01 0.0000000e+00 4.0955089e-07 9.6435460e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[9.9999952e-01 0.0000000e+00 4.3592223e-07 8.4626479e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[9.9999952e-01 0.0000000e+00 4.3795069e-07 9.3962856e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[9.9999964e-01 0.0000000e+00 4.0554377e-07 7.7291309e-14]]\n",
      "0\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[9.9999964e-01 0.0000000e+00 3.5726708e-07 6.5550762e-14]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_equalvideos_savedmodel_epoch20_accuracy.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    'HighDanger':3,\n",
    "    'LowDanger': 1,\n",
    "    'MediumDanger': 2,\n",
    "    'Normal': 0\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\Harshi\\Downloads\\production_id_4052825 (2160p).mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "    print(predictions)\n",
    "\n",
    "#     # Convert predictions to class labels using class_mapping\n",
    "#     predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "#     # Check if the predicted label index is in class_mapping\n",
    "#     if predicted_label_index in class_mapping:\n",
    "#         predicted_label = class_mapping[predicted_label_index]\n",
    "#     else:\n",
    "# #         print(f\"Unexpected predicted label index: {predicted_label_index}\")\n",
    "#         predicted_label = 0\n",
    "\n",
    "    predicted_label_index=np.argmax(predictions)\n",
    "    print(predicted_label_index)\n",
    "    \n",
    "    keys_list=list(class_mapping.keys())\n",
    "    \n",
    "    key_at_index = keys_list[predicted_label_index]\n",
    "    value_at_index = class_mapping[key_at_index]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {value_at_index}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32254c12",
   "metadata": {},
   "source": [
    "# TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae73e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HighDanger', 'LowDanger', 'MediumDanger', 'Normal']\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 4)    256         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 4)            0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 4)            0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 229,472\n",
      "Trainable params: 228,288\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Found 66110 images belonging to 4 classes.\n",
      "Found 21368 images belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "4132/4132 [==============================] - 239s 57ms/step - loss: 0.7368 - accuracy: 0.6874 - val_loss: 1.0011 - val_accuracy: 0.5936\n",
      "Epoch 2/10\n",
      "4132/4132 [==============================] - 204s 49ms/step - loss: 0.6502 - accuracy: 0.7268 - val_loss: 0.9778 - val_accuracy: 0.5279\n",
      "Epoch 3/10\n",
      "4132/4132 [==============================] - 209s 50ms/step - loss: 0.6102 - accuracy: 0.7528 - val_loss: 2.0524 - val_accuracy: 0.4712\n",
      "Epoch 4/10\n",
      "4132/4132 [==============================] - 211s 51ms/step - loss: 0.5699 - accuracy: 0.7775 - val_loss: 1.2268 - val_accuracy: 0.5271\n",
      "Epoch 5/10\n",
      "4132/4132 [==============================] - 215s 52ms/step - loss: 0.5383 - accuracy: 0.7961 - val_loss: 1.2748 - val_accuracy: 0.6105\n",
      "Epoch 6/10\n",
      "4132/4132 [==============================] - 220s 53ms/step - loss: 0.5140 - accuracy: 0.8102 - val_loss: 1.5246 - val_accuracy: 0.5545\n",
      "Epoch 7/10\n",
      "4132/4132 [==============================] - 225s 54ms/step - loss: 0.4883 - accuracy: 0.8247 - val_loss: 1.2261 - val_accuracy: 0.5678\n",
      "Epoch 8/10\n",
      "4132/4132 [==============================] - 219s 53ms/step - loss: 0.4713 - accuracy: 0.8356 - val_loss: 1.5177 - val_accuracy: 0.5841\n",
      "Epoch 9/10\n",
      "4132/4132 [==============================] - 220s 53ms/step - loss: 0.4580 - accuracy: 0.8466 - val_loss: 2.1658 - val_accuracy: 0.5213\n",
      "Epoch 10/10\n",
      "4132/4132 [==============================] - 223s 54ms/step - loss: 0.4458 - accuracy: 0.8533 - val_loss: 1.3750 - val_accuracy: 0.5944\n",
      "334/334 [==============================] - 25s 74ms/step - loss: 1.3750 - accuracy: 0.5944\n",
      "334/334 [==============================] - 24s 73ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  HighDanger       0.24      0.28      0.26      5225\n",
      "   LowDanger       0.12      0.06      0.08      2793\n",
      "MediumDanger       0.35      0.38      0.36      7413\n",
      "      Normal       0.27      0.27      0.27      5937\n",
      "\n",
      "    accuracy                           0.28     21368\n",
      "   macro avg       0.24      0.25      0.24     21368\n",
      "weighted avg       0.27      0.28      0.28     21368\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1444  339 1989 1453]\n",
      " [ 766  163 1071  793]\n",
      " [2040  502 2811 2060]\n",
      " [1677  412 2225 1623]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "class_labels = [\n",
    "    'HighDanger', 'LowDanger', 'MediumDanger', 'Normal'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\LEVEL_AHAR\\Train'\n",
    "validation1_data = r'D:\\LEVEL_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Calculate class weights\n",
    "# class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(training_set.classes), y=training_set.classes)\n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "# print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Model compilation with class weights\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with class weights\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set),\n",
    "#     class_weight=class_weight_dict  # Pass the calculated class weights\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "model.save('AHAR_lesshighvideos_savedmodel_epoch10_accuracy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84de19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 145ms/step\n",
      "[[1.7068535e-02 2.8364567e-02 1.8642393e-04 9.5438045e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[2.0842317e-02 3.2004502e-02 2.2088885e-04 9.4693232e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[1.9903600e-02 2.8871441e-02 2.3366143e-04 9.5099133e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[2.0735212e-02 3.0619670e-02 2.6221847e-04 9.4838291e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[2.0597421e-02 3.5137262e-02 2.7300944e-04 9.4399226e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[2.2707254e-02 4.5613043e-02 3.0853850e-04 9.3137121e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[2.0294096e-02 4.4110857e-02 2.8600535e-04 9.3530905e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[2.7335843e-02 5.8119167e-02 4.0854586e-04 9.1413647e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[2.5210032e-02 5.2671529e-02 3.8897476e-04 9.2172945e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[2.6275147e-02 5.0683271e-02 4.2049977e-04 9.2262113e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[2.5403766e-02 3.8816907e-02 3.9282328e-04 9.3538654e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[2.5774496e-02 3.6082238e-02 4.0656305e-04 9.3773669e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[2.7346706e-02 3.8329169e-02 4.1481928e-04 9.3390936e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[3.1946547e-02 4.2915866e-02 4.4172150e-04 9.2469591e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[3.3596355e-02 4.6282314e-02 4.6979825e-04 9.1965157e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[3.8994838e-02 5.3345948e-02 5.6492514e-04 9.0709436e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[3.9476205e-02 5.3485088e-02 5.7418685e-04 9.0646446e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[4.3987636e-02 6.1722267e-02 6.4914284e-04 8.9364088e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[3.8905866e-02 5.7212818e-02 5.6819693e-04 9.0331310e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[4.1062746e-02 6.1519507e-02 6.1409024e-04 8.9680362e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[3.8929962e-02 6.0468920e-02 5.8727461e-04 9.0001386e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[4.1905928e-02 6.3168965e-02 6.4162130e-04 8.9428347e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[4.0400647e-02 5.9653990e-02 6.1291980e-04 8.9933246e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[4.0470358e-02 5.9068725e-02 5.9119018e-04 8.9986974e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[3.5156906e-02 5.1947273e-02 5.3617795e-04 9.1235965e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[3.4684636e-02 4.8804294e-02 5.3122995e-04 9.1597992e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[3.632422e-02 5.104775e-02 5.568983e-04 9.120711e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[3.3145569e-02 4.6321150e-02 5.0669402e-04 9.2002654e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[3.3735432e-02 4.6480108e-02 5.1657826e-04 9.1926789e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[2.7061898e-02 3.8835589e-02 4.2068865e-04 9.3368179e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[2.6915852e-02 4.4217434e-02 4.1146509e-04 9.2845523e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[2.1369072e-02 3.7804943e-02 3.0790115e-04 9.4051808e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[2.2761205e-02 3.5872541e-02 3.3634456e-04 9.4102991e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[2.3580551e-02 3.6244053e-02 3.5240321e-04 9.3982309e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[2.8797407e-02 3.9743140e-02 4.3880116e-04 9.3102056e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[3.0760927e-02 3.5020854e-02 4.9999042e-04 9.3371826e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[3.0111944e-02 4.3638315e-02 4.4171617e-04 9.2580807e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[3.4330755e-02 6.1341215e-02 4.5998176e-04 9.0386808e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[4.2889822e-02 8.0016829e-02 5.3952954e-04 8.7655383e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[4.3219607e-02 8.0000959e-02 5.3732615e-04 8.7624210e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[5.1531013e-02 9.5507473e-02 6.2682189e-04 8.5233468e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[4.7679164e-02 9.7040355e-02 5.9590145e-04 8.5468459e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[5.6226503e-02 1.0938394e-01 7.6698320e-04 8.3362257e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[5.1870957e-02 1.0181114e-01 6.7412207e-04 8.4564382e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[5.4387279e-02 1.1101193e-01 7.0705626e-04 8.3389372e-01]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.06874648 0.14821258 0.00084729 0.78219366]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.07906168 0.18985574 0.00103888 0.7300437 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.08899632 0.20878899 0.00132131 0.7008934 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.09149434 0.20944448 0.00140362 0.6976576 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0.10093545 0.22276683 0.00152143 0.67477626]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.09637512 0.19428664 0.00139781 0.7079404 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0.10808463 0.19933492 0.00164257 0.6909379 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.11626638 0.20634577 0.00173286 0.675655  ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.10764492 0.19667287 0.00150869 0.6941735 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.12808344 0.2090991  0.00172444 0.661093  ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.14579427 0.22858803 0.00194609 0.6236716 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.15058397 0.23292491 0.00215344 0.6143376 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.15406391 0.24220602 0.00225779 0.6014723 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.15377255 0.24072292 0.00232983 0.6031747 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.15502049 0.23982847 0.00225756 0.6028935 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.14796273 0.24390754 0.00217041 0.60595936]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.13662615 0.2445243  0.00197111 0.61687845]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.1498809  0.26661208 0.00216759 0.5813394 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.16091841 0.28809097 0.00252269 0.54846793]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.16659503 0.3589596  0.00253677 0.47190863]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.16745983 0.38732412 0.00239425 0.44282183]]\n",
      "3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.161193   0.39609423 0.00234403 0.44036874]]\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.15770094 0.44293168 0.00212598 0.39724144]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.13701151 0.42199072 0.00190262 0.4390952 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.1493257  0.4461939  0.00216426 0.40231603]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.17409186 0.42856947 0.00254266 0.39479598]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.17972258 0.4021887  0.00263727 0.41545147]]\n",
      "3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.1727682  0.39717788 0.00276694 0.42728692]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.15764879 0.34656236 0.00282739 0.49296153]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.1326919  0.31802323 0.00263872 0.5466461 ]]\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.11450103 0.282843   0.00234611 0.6003099 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.09863527 0.2667932  0.00216295 0.6324085 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.09527094 0.23552622 0.00219831 0.6670045 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.11929695 0.23953937 0.00276057 0.6384031 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.14853264 0.2563505  0.00354768 0.5915692 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.17385826 0.32011577 0.00375275 0.5022732 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.18791538 0.35798243 0.00372653 0.45037562]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.1821145  0.40055877 0.00335817 0.4139686 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.16223598 0.45820865 0.00272451 0.37683088]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.14321117 0.4585424  0.00232647 0.39591992]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.1268167  0.4213532  0.00218838 0.44964173]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.13179587 0.394686   0.00240754 0.47111046]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.13641334 0.3728789  0.00262963 0.4880782 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.15164916 0.33022085 0.00298604 0.51514393]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.16893221 0.2975333  0.00341255 0.5301219 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.16715182 0.29452255 0.00326997 0.53505564]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.15859191 0.30379844 0.00302478 0.5345849 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.1603977  0.32301265 0.00302132 0.51356834]]\n",
      "3\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.15657632 0.3260412  0.00297425 0.5144083 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.16671772 0.34763262 0.00310388 0.4825458 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.16973546 0.3490969  0.00320391 0.47796366]]\n",
      "3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.17744897 0.34941477 0.00371942 0.46941686]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.1764021  0.32657236 0.00394826 0.49307725]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.1855956  0.35067284 0.00398704 0.45974448]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.17720796 0.34937418 0.00357697 0.46984088]]\n",
      "3\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.1783552  0.33916894 0.00372863 0.47874722]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.18992707 0.34658635 0.00360657 0.45988008]]\n",
      "3\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.21731642 0.3639395  0.0039023  0.41484183]]\n",
      "3\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.2277323  0.36683503 0.00404629 0.4013864 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.22825594 0.3566641  0.00389234 0.41118756]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.25390553 0.36441088 0.00462224 0.3770613 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.30565843 0.40025452 0.0057128  0.2883742 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.33073267 0.4103261  0.00631084 0.25263032]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.3391654  0.4313719  0.00639149 0.22307126]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.33584055 0.4491979  0.00647868 0.20848288]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.33578065 0.45488232 0.00625423 0.20308274]]\n",
      "1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.2935508  0.46889105 0.0051943  0.23236383]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.26006043 0.4627103  0.00416212 0.27306724]]\n",
      "1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.25740334 0.39240342 0.0038861  0.34630716]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.24824946 0.35624704 0.00340609 0.39209744]]\n",
      "3\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.25792685 0.34205028 0.00322155 0.39680126]]\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.26924783 0.35518458 0.00329964 0.372268  ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.27271858 0.37945318 0.00304856 0.3447797 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.25117713 0.399409   0.00290145 0.34651244]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.26443085 0.35466316 0.00270853 0.3781975 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.269903   0.37474433 0.00256443 0.35278824]]\n",
      "1\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.26128042 0.37502962 0.00233227 0.36135772]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.23728758 0.38760588 0.00222517 0.37288138]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.21296741 0.42051727 0.00223257 0.36428267]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.1859279  0.41650024 0.00213552 0.3954363 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.18224569 0.42855898 0.00217758 0.38701776]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.22221711 0.48991895 0.00256086 0.28530306]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.22141601 0.49092877 0.00259403 0.28506115]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.20727135 0.4636101  0.00273768 0.3263809 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.21218805 0.41815397 0.00308115 0.36657682]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.21165791 0.42387086 0.00268091 0.36179033]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.21783327 0.4166504  0.00276719 0.36274916]]\n",
      "1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.21526587 0.43450576 0.00259898 0.34762943]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.205193   0.48014855 0.0020159  0.31264263]]\n",
      "1\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.19564655 0.51660466 0.00169448 0.28605425]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.19838423 0.5614044  0.00152288 0.23868848]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.21196234 0.59153223 0.00137662 0.1951288 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0.23207049 0.5927213  0.00145769 0.17375052]]\n",
      "1\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[0.23657769 0.6074191  0.0013797  0.15462354]]\n",
      "1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.24580558 0.6003058  0.00138458 0.15250407]]\n",
      "1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.26220614 0.58272886 0.00150413 0.15356085]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.26556757 0.5429547  0.00150988 0.18996783]]\n",
      "1\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.26950625 0.5143694  0.00154824 0.21457613]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.26619318 0.4878816  0.00154892 0.24437633]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.28411382 0.47621158 0.00170703 0.23796754]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.28992558 0.45249987 0.00183509 0.25573954]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.2871375  0.43966502 0.00182121 0.2713763 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.26791668 0.43000457 0.00175928 0.3003195 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.24896397 0.4372531  0.00158231 0.31220058]]\n",
      "1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.23358496 0.40840912 0.00159993 0.356406  ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.22057725 0.37359968 0.0015674  0.4042557 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.2045045  0.34435523 0.0014769  0.44966337]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.19661988 0.32723603 0.00142633 0.47471786]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.18847005 0.32411543 0.00135853 0.48605594]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.1842781  0.35133436 0.00127973 0.46310785]]\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.17973465 0.3344883  0.00118458 0.48459238]]\n",
      "3\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.18124077 0.34040222 0.00116607 0.4771909 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.18824027 0.36942682 0.00122752 0.4411054 ]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.19160822 0.3629453  0.00133332 0.44411322]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.20371638 0.38307205 0.00143485 0.41177675]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.20398983 0.39053047 0.00141305 0.40406662]]\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.21111864 0.4082712  0.00143021 0.37917992]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21312489 0.40281284 0.00151164 0.3825506 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21999818 0.41611612 0.00164984 0.36223584]]\n",
      "1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.22011715 0.42208618 0.00160673 0.35618988]]\n",
      "1\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.22154003 0.45042828 0.00157384 0.3264578 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21602571 0.46434438 0.00145521 0.31817475]]\n",
      "1\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[0.2142878  0.47345504 0.00142057 0.31083667]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21403293 0.4565916  0.00145221 0.32792324]]\n",
      "1\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.21381582 0.46131483 0.00143244 0.3234369 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.20388073 0.4397603  0.00138316 0.3549758 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.20405908 0.42942834 0.00138498 0.36512756]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.20450619 0.4232311  0.00136351 0.37089926]]\n",
      "1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.20641606 0.42758775 0.00133843 0.3646578 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.19252963 0.41211674 0.00125032 0.3941033 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.18812597 0.4049276  0.00128784 0.40565854]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.18694055 0.40674737 0.00123886 0.40507323]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.1780288  0.39130503 0.00123584 0.42943028]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.18255943 0.38414773 0.00135663 0.43193617]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.18294135 0.36385897 0.00147896 0.45172074]]\n",
      "3\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[0.17865789 0.39074683 0.00136796 0.42922726]]\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.19194956 0.41580483 0.00145948 0.39078608]]\n",
      "1\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.20999743 0.44964936 0.00155418 0.33879903]]\n",
      "1\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0.22382952 0.4783879  0.00168746 0.29609513]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.2277376  0.5077424  0.00160268 0.26291728]]\n",
      "1\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.24743158 0.5149862  0.00172563 0.23585658]]\n",
      "1\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.2552421  0.5185246  0.00179171 0.22444157]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.2448721  0.5158778  0.00174192 0.23750815]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.22684358 0.51208    0.00166445 0.25941202]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.22032693 0.48302358 0.00180985 0.2948396 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.22750619 0.49827504 0.00186351 0.27235517]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.23028469 0.50609    0.00184272 0.26178265]]\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.22818634 0.5257527  0.00172846 0.24433242]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.22084127 0.5419839  0.00171013 0.23546472]]\n",
      "1\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.22191873 0.57499236 0.00171969 0.20136923]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.2222217  0.5943498  0.00167633 0.18175219]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.25626725 0.6129006  0.00196351 0.12886864]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.28205246 0.58924896 0.00222511 0.12647349]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.27608973 0.6019477  0.00251458 0.11944799]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.2880436  0.5845244  0.00250375 0.12492827]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.314271   0.5417054  0.00297318 0.1410504 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.34673187 0.47865528 0.00326642 0.17134641]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.36298126 0.46902573 0.00350354 0.16448945]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.36995405 0.4625395  0.00363045 0.163876  ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.3826335  0.43386236 0.00389082 0.1796133 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.3761675  0.44846377 0.00372269 0.17164601]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.36079064 0.4394155  0.00384045 0.19595337]]\n",
      "1\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.34670895 0.4373392  0.00376514 0.2121868 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0.34300917 0.44785964 0.00368196 0.20544922]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.33333772 0.46477023 0.00317251 0.19871955]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.3177732  0.50271755 0.00268421 0.176825  ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.29411885 0.500301   0.00275224 0.20282793]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.2716073  0.45428678 0.00290607 0.27119985]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.25954998 0.43679893 0.0031989  0.3004522 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.26852012 0.3946123  0.00378822 0.3330793 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0.2500563  0.38319457 0.00359792 0.3631512 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21284738 0.3939831  0.00253522 0.3906343 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.20533516 0.40917283 0.00226233 0.3832296 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.198938   0.42399547 0.00217042 0.3748961 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.20736444 0.46147045 0.00214077 0.32902437]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21227086 0.48132947 0.00207998 0.30431974]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21684538 0.4964303  0.00207817 0.28464612]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.21812935 0.50868636 0.00199091 0.2711934 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.23032704 0.50935763 0.00196372 0.2583516 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.22597592 0.49025258 0.00184841 0.28192317]]\n",
      "1\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.22318922 0.46519595 0.00173343 0.3098814 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.22779815 0.47038504 0.00171012 0.30010667]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.22574657 0.45545274 0.00172082 0.31707984]]\n",
      "1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.23384793 0.43427378 0.00189962 0.32997862]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.24511766 0.40960932 0.00221531 0.34305772]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.26592124 0.39532176 0.00267352 0.3360835 ]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.28023413 0.37842372 0.00320567 0.33813646]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.28662893 0.41315475 0.00345296 0.29676342]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.28547543 0.44824532 0.00340248 0.2628768 ]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_lesshighvideos_savedmodel_epoch10_accuracy.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    'HighDanger':3,\n",
    "    'LowDanger': 1,\n",
    "    'MediumDanger': 2,\n",
    "    'Normal': 0\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\Harshi\\Downloads\\production_id_4052825 (2160p).mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "    print(predictions)\n",
    "\n",
    "#     # Convert predictions to class labels using class_mapping\n",
    "#     predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "#     # Check if the predicted label index is in class_mapping\n",
    "#     if predicted_label_index in class_mapping:\n",
    "#         predicted_label = class_mapping[predicted_label_index]\n",
    "#     else:\n",
    "# #         print(f\"Unexpected predicted label index: {predicted_label_index}\")\n",
    "#         predicted_label = 0\n",
    "\n",
    "    predicted_label_index=np.argmax(predictions)\n",
    "    print(predicted_label_index)\n",
    "    \n",
    "    keys_list=list(class_mapping.keys())\n",
    "    \n",
    "    key_at_index = keys_list[predicted_label_index]\n",
    "    value_at_index = class_mapping[key_at_index]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {value_at_index}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff1879",
   "metadata": {},
   "source": [
    "# TEST 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a551b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism']\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_6[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n",
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,112\n",
      "Trainable params: 228,928\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 160, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sep_conv1 (Conv2D)             (None, 160, 160, 32  1568        ['input_6[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 160, 160, 32  128         ['sep_conv1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 160, 160, 32  0           ['bn1[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " mp1 (MaxPooling2D)             (None, 80, 80, 32)   0           ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv2 (Conv2D)             (None, 80, 80, 48)   13824       ['mp1[0][0]']                    \n",
      "                                                                                                  \n",
      " bn2 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv2[0][0]']              \n",
      "                                                                                                  \n",
      " relu2 (Activation)             (None, 80, 80, 48)   0           ['bn2[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv3 (Conv2D)             (None, 80, 80, 48)   20736       ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " bn3 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv3[0][0]']              \n",
      "                                                                                                  \n",
      " relu3 (Activation)             (None, 80, 80, 48)   0           ['bn3[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv4 (Conv2D)             (None, 80, 80, 48)   20736       ['relu3[0][0]']                  \n",
      "                                                                                                  \n",
      " bn4 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv4[0][0]']              \n",
      "                                                                                                  \n",
      " relu4 (Activation)             (None, 80, 80, 48)   0           ['bn4[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv5 (Conv2D)             (None, 80, 80, 48)   20736       ['relu4[0][0]']                  \n",
      "                                                                                                  \n",
      " bn5 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv5[0][0]']              \n",
      "                                                                                                  \n",
      " relu5 (Activation)             (None, 80, 80, 48)   0           ['bn5[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 80, 80, 80)   0           ['mp1[0][0]',                    \n",
      "                                                                  'relu5[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv6 (Conv2D)             (None, 80, 80, 48)   3840        ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " bn6 (BatchNormalization)       (None, 80, 80, 48)   192         ['sep_conv6[0][0]']              \n",
      "                                                                                                  \n",
      " relu6 (Activation)             (None, 80, 80, 48)   0           ['bn6[0][0]']                    \n",
      "                                                                                                  \n",
      " mp2 (MaxPooling2D)             (None, 40, 40, 48)   0           ['relu6[0][0]']                  \n",
      "                                                                                                  \n",
      " sep_conv7 (Conv2D)             (None, 40, 40, 64)   27648       ['mp2[0][0]']                    \n",
      "                                                                                                  \n",
      " bn7 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv7[0][0]']              \n",
      "                                                                                                  \n",
      " relu7 (Activation)             (None, 40, 40, 64)   0           ['bn7[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv8 (Conv2D)             (None, 40, 40, 64)   36864       ['relu7[0][0]']                  \n",
      "                                                                                                  \n",
      " bn8 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv8[0][0]']              \n",
      "                                                                                                  \n",
      " relu8 (Activation)             (None, 40, 40, 64)   0           ['bn8[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv9 (Conv2D)             (None, 40, 40, 64)   36864       ['relu8[0][0]']                  \n",
      "                                                                                                  \n",
      " bn9 (BatchNormalization)       (None, 40, 40, 64)   256         ['sep_conv9[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " relu9 (Activation)             (None, 40, 40, 64)   0           ['bn9[0][0]']                    \n",
      "                                                                                                  \n",
      " sep_conv10 (Conv2D)            (None, 40, 40, 64)   36864       ['relu9[0][0]']                  \n",
      "                                                                                                  \n",
      " bn10 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv10[0][0]']             \n",
      "                                                                                                  \n",
      " relu10 (Activation)            (None, 40, 40, 64)   0           ['bn10[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 40, 40, 112)  0           ['mp2[0][0]',                    \n",
      "                                                                  'relu10[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv11 (Conv2D)            (None, 40, 40, 64)   7168        ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " bn11 (BatchNormalization)      (None, 40, 40, 64)   256         ['sep_conv11[0][0]']             \n",
      "                                                                                                  \n",
      " relu11 (Activation)            (None, 40, 40, 64)   0           ['bn11[0][0]']                   \n",
      "                                                                                                  \n",
      " mp3 (MaxPooling2D)             (None, 20, 20, 64)   0           ['relu11[0][0]']                 \n",
      "                                                                                                  \n",
      " sep_conv22 (Conv2D)            (None, 20, 20, 14)   896         ['mp3[0][0]']                    \n",
      "                                                                                                  \n",
      " gap1 (GlobalAveragePooling2D)  (None, 14)           0           ['sep_conv22[0][0]']             \n",
      "                                                                                                  \n",
      " softmax1 (Activation)          (None, 14)           0           ['gap1[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 230,112\n",
      "Trainable params: 228,928\n",
      "Non-trainable params: 1,184\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Found 62909 images belonging to 14 classes.\n",
      "Found 13079 images belonging to 14 classes.\n",
      "Epoch 1/10\n",
      "3932/3932 [==============================] - 981s 249ms/step - loss: 2.1521 - accuracy: 0.3239 - val_loss: 3.3001 - val_accuracy: 0.1691\n",
      "Epoch 2/10\n",
      "3932/3932 [==============================] - 183s 47ms/step - loss: 1.8414 - accuracy: 0.4452 - val_loss: 3.3382 - val_accuracy: 0.1853\n",
      "Epoch 3/10\n",
      "3932/3932 [==============================] - 187s 47ms/step - loss: 1.5774 - accuracy: 0.5487 - val_loss: 3.5711 - val_accuracy: 0.2035\n",
      "Epoch 4/10\n",
      "3932/3932 [==============================] - 191s 49ms/step - loss: 1.3769 - accuracy: 0.6267 - val_loss: 3.5516 - val_accuracy: 0.2539\n",
      "Epoch 5/10\n",
      "3932/3932 [==============================] - 195s 50ms/step - loss: 1.2296 - accuracy: 0.6821 - val_loss: 3.5805 - val_accuracy: 0.2693\n",
      "Epoch 6/10\n",
      "3932/3932 [==============================] - 195s 50ms/step - loss: 1.1366 - accuracy: 0.7151 - val_loss: 3.6429 - val_accuracy: 0.2564\n",
      "Epoch 7/10\n",
      "3932/3932 [==============================] - 199s 51ms/step - loss: 1.0679 - accuracy: 0.7442 - val_loss: 4.2877 - val_accuracy: 0.2070\n",
      "Epoch 8/10\n",
      "3932/3932 [==============================] - 199s 51ms/step - loss: 1.0160 - accuracy: 0.7639 - val_loss: 3.9771 - val_accuracy: 0.2347\n",
      "Epoch 9/10\n",
      "3932/3932 [==============================] - 199s 51ms/step - loss: 0.9878 - accuracy: 0.7746 - val_loss: 4.0509 - val_accuracy: 0.3034\n",
      "Epoch 10/10\n",
      "3932/3932 [==============================] - 201s 51ms/step - loss: 0.9642 - accuracy: 0.7866 - val_loss: 5.1703 - val_accuracy: 0.1728\n",
      "205/205 [==============================] - 15s 74ms/step - loss: 5.1703 - accuracy: 0.1728\n",
      "205/205 [==============================] - 15s 72ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Abuse       0.07      0.01      0.02      1000\n",
      "       Arrest       0.07      0.02      0.04      1000\n",
      "        Arson       0.12      0.14      0.13      1474\n",
      "      Assault       0.09      0.02      0.03       922\n",
      "     Burglary       0.07      0.05      0.06      1000\n",
      "    Explosion       0.07      0.02      0.03       993\n",
      "     Fighting       0.07      0.44      0.13      1000\n",
      " NormalVideos       0.05      0.05      0.05       800\n",
      "RoadAccidents       0.08      0.01      0.03      1000\n",
      "      Robbery       0.06      0.03      0.04      1000\n",
      "     Shooting       0.03      0.00      0.00       500\n",
      "  Shoplifting       0.00      0.00      0.00       755\n",
      "     Stealing       0.06      0.02      0.03       820\n",
      "    Vandalism       0.07      0.19      0.10       815\n",
      "\n",
      "     accuracy                           0.08     13079\n",
      "    macro avg       0.07      0.07      0.05     13079\n",
      " weighted avg       0.07      0.08      0.05     13079\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 10  26 132  17  43  16 454  69  22  30   2   1  20 158]\n",
      " [ 10  24 125  14  62  18 449  71  13  39   0   1  17 157]\n",
      " [ 12  36 211  16  76  23 684  67  24  49   5   0  29 242]\n",
      " [  7  32 119  18  32  17 428  44  11  29   4   2  13 166]\n",
      " [ 13  29 135  21  46  22 443  60  11  32   3   1  24 160]\n",
      " [  8  30 120  15  43  19 471  60  14  42   2   0  12 157]\n",
      " [ 14  32 133  16  49  18 437  52  21  30   2   2  18 176]\n",
      " [ 15  17 106  14  36  21 357  40  14  26   5   0  13 136]\n",
      " [ 12  22 134  20  49  30 420  68  15  35   2   2  23 168]\n",
      " [  8  18 134  18  54  26 466  57  12  26   3   1  26 151]\n",
      " [  7  14  60   7  19   7 217  34   9  23   1   0  11  91]\n",
      " [ 15  27  92   9  43  12 328  38  10  31   2   0  14 134]\n",
      " [  8  21  94   8  40  23 391  42   9  28   2   0  14 140]\n",
      " [  9  15 107  11  28  18 375  50  11  23   1   1  11 155]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Dropout, Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img,array_to_img\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "\n",
    "class_labels = [\n",
    "    'Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting',\n",
    "    'NormalVideos', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Stealing', 'Vandalism'\n",
    "]\n",
    "\n",
    "train1_data = r'D:\\OUTPUT_AHAR\\Train'\n",
    "validation1_data = r'D:\\OUTPUT_AHAR\\Test'\n",
    "IMG_SIZE = 160\n",
    "LR = 1e-3\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "\n",
    "x5 = class_labels.copy()\n",
    "print(class_labels)\n",
    "\n",
    "input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "# Block 1\n",
    "layer0 = Conv2D(32, (7, 7), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv1')(input)\n",
    "layer0 = BatchNormalization(name='bn1')(layer0)\n",
    "layer0 = Activation('relu', name='relu1')(layer0)\n",
    "layer0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp1')(layer0)\n",
    "\n",
    "skip_connection_1 = layer0\n",
    "\n",
    "# Block 2\n",
    "layer1 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv2')(layer0)\n",
    "layer1 = BatchNormalization(name='bn2')(layer1)\n",
    "layer1 = Activation('relu', name='relu2')(layer1)\n",
    "\n",
    "layer2 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv3')(layer1)\n",
    "layer2 = BatchNormalization(name='bn3')(layer2)\n",
    "layer2 = Activation('relu', name='relu3')(layer2)\n",
    "\n",
    "layer3 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv4')(layer2)\n",
    "layer3 = BatchNormalization(name='bn4')(layer3)\n",
    "layer3 = Activation('relu', name='relu4')(layer3)\n",
    "\n",
    "layer4 = Conv2D(48, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv5')(layer3)\n",
    "layer4 = BatchNormalization(name='bn5')(layer4)\n",
    "layer4 = Activation('relu', name='relu5')(layer4)\n",
    "\n",
    "layer5 = keras.layers.concatenate([skip_connection_1, layer4])\n",
    "layer5 = Conv2D(48, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv6')(layer5)\n",
    "layer5 = BatchNormalization(name='bn6')(layer5)\n",
    "layer5 = Activation('relu', name='relu6')(layer5)\n",
    "layer5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp2')(layer5)\n",
    "\n",
    "skip_connection_2 = layer5\n",
    "\n",
    "# Block 3\n",
    "layer6 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv7')(layer5)\n",
    "layer6 = BatchNormalization(name='bn7')(layer6)\n",
    "layer6 = Activation('relu', name='relu7')(layer6)\n",
    "\n",
    "layer7 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv8')(layer6)\n",
    "layer7 = BatchNormalization(name='bn8')(layer7)\n",
    "layer7 = Activation('relu', name='relu8')(layer7)\n",
    "\n",
    "layer8 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv9')(layer7)\n",
    "layer8 = BatchNormalization(name='bn9')(layer8)\n",
    "layer8 = Activation('relu', name='relu9')(layer8)\n",
    "\n",
    "layer9 = Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv10')(layer8)\n",
    "layer9 = BatchNormalization(name='bn10')(layer9)\n",
    "layer9 = Activation('relu', name='relu10')(layer9)\n",
    "\n",
    "layer10 = keras.layers.concatenate([skip_connection_2, layer9])\n",
    "layer10 = Conv2D(64, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv11')(layer10)\n",
    "layer10 = BatchNormalization(name='bn11')(layer10)\n",
    "layer10 = Activation('relu', name='relu11')(layer10)\n",
    "layer10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='mp3')(layer10)\n",
    "\n",
    "skip_connection_3 = layer10\n",
    "\n",
    "# Output block\n",
    "layer21 = Conv2D(num_classes, (1, 1), kernel_regularizer=keras.regularizers.l2(1e-4), use_bias=False, kernel_initializer='he_normal', name='sep_conv22')(layer10)\n",
    "layer21 = GlobalAveragePooling2D(name='gap1')(layer21)\n",
    "\n",
    "output = Activation('softmax', name='softmax1')(layer21)\n",
    "\n",
    "epochs1 = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs1\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Image data generator with preprocessing steps\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=0.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    \n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    shuffle=True,\n",
    "    subset='training',  # Specify that this is the training subset\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    validation1_data,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    classes=x5,\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Set color_mode to 'grayscale' for single-channel images\n",
    "    interpolation='bilinear',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(test_set, steps=len(test_set))\n",
    "\n",
    "# Extract predictions and true labels\n",
    "predictions = model.predict(test_set, steps=len(test_set))\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "model.save('AHAR_new13videos_savedmodel_epoch10_accuracy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d75aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7417386e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1383712e-22 0.0000000e+00\n",
      "  0.0000000e+00 3.1662454e-29 0.0000000e+00 1.0190777e-30]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3679827e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 9.1403243e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.2594508e-28 0.0000000e+00 3.5880568e-30]]\n",
      "1\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.0263694e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.9004383e-23 0.0000000e+00\n",
      "  0.0000000e+00 9.2711042e-29 0.0000000e+00 4.2639149e-30]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.4554464e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.0414143e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.1858828e-28 0.0000000e+00 9.8090193e-30]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4446195e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5632618e-22 0.0000000e+00\n",
      "  0.0000000e+00 1.8371737e-27 0.0000000e+00 7.6486942e-29]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.4425160e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7270278e-22 0.0000000e+00\n",
      "  0.0000000e+00 8.0202363e-27 0.0000000e+00 1.6091424e-28]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3608464e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.8614239e-22 0.0000000e+00\n",
      "  0.0000000e+00 2.2768788e-26 0.0000000e+00 1.2758046e-28]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2806607e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 7.7191535e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.9444072e-26 0.0000000e+00 1.9307904e-28]]\n",
      "1\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0657252e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 6.4768876e-23 0.0000000e+00\n",
      "  0.0000000e+00 2.4783356e-26 0.0000000e+00 6.0813251e-28]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4559719e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3447295e-23 0.0000000e+00\n",
      "  0.0000000e+00 6.1731638e-26 0.0000000e+00 3.1552765e-27]]\n",
      "1\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3882892e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1991238e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.7967821e-25 0.0000000e+00 3.8860656e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5040517e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3440020e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.8473657e-25 0.0000000e+00 1.3512419e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 8.8723522e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3488149e-23 0.0000000e+00\n",
      "  0.0000000e+00 9.4391694e-25 0.0000000e+00 6.3788022e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6832142e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.8967569e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.4371783e-24 0.0000000e+00 5.7178149e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.2850308e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2780810e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.9523246e-24 0.0000000e+00 6.7147564e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5029640e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.9729601e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.4393728e-24 0.0000000e+00 1.9311920e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.4153275e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 8.7857724e-23 0.0000000e+00\n",
      "  0.0000000e+00 2.7204271e-24 0.0000000e+00 7.8079961e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.1150381e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.1136625e-22 0.0000000e+00\n",
      "  0.0000000e+00 4.8004864e-24 0.0000000e+00 1.4623694e-23]]\n",
      "1\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2146173e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2291489e-22 0.0000000e+00\n",
      "  0.0000000e+00 1.8298672e-24 0.0000000e+00 2.9977484e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.5608132e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1478542e-22 0.0000000e+00\n",
      "  0.0000000e+00 8.2003653e-24 0.0000000e+00 9.3456249e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.5096285e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7048357e-22 0.0000000e+00\n",
      "  0.0000000e+00 7.7265739e-24 0.0000000e+00 2.9487968e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8234378e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0532063e-22 0.0000000e+00\n",
      "  0.0000000e+00 1.9245879e-24 0.0000000e+00 4.1530465e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6360639e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4973235e-22 0.0000000e+00\n",
      "  0.0000000e+00 1.7187717e-24 0.0000000e+00 7.0816492e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9089329e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6007686e-22 0.0000000e+00\n",
      "  0.0000000e+00 4.0402411e-24 0.0000000e+00 1.4636523e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2713615e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2870810e-22 0.0000000e+00\n",
      "  0.0000000e+00 4.3026517e-24 0.0000000e+00 5.2880336e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.2791436e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.4272917e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.2402586e-24 0.0000000e+00 4.0098395e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6777556e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.3719451e-23 0.0000000e+00\n",
      "  0.0000000e+00 8.2501238e-25 0.0000000e+00 3.9351182e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 8.6460857e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 6.5962479e-23 0.0000000e+00\n",
      "  0.0000000e+00 6.8971558e-25 0.0000000e+00 4.0758293e-24]]\n",
      "1\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3931045e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4395164e-23 0.0000000e+00\n",
      "  0.0000000e+00 2.3062600e-25 0.0000000e+00 4.1582140e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6448050e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1857818e-23 0.0000000e+00\n",
      "  0.0000000e+00 2.2676485e-25 0.0000000e+00 1.9935887e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6021908e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5592397e-23 0.0000000e+00\n",
      "  0.0000000e+00 5.8233618e-25 0.0000000e+00 1.7714509e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.0348764e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1119647e-23 0.0000000e+00\n",
      "  0.0000000e+00 7.1458541e-25 0.0000000e+00 2.3630780e-25]]\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.9514118e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3283521e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.1784400e-24 0.0000000e+00 1.0036292e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.1963635e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5611322e-23 0.0000000e+00\n",
      "  0.0000000e+00 9.2125652e-25 0.0000000e+00 5.8183404e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3343772e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9998067e-24 0.0000000e+00\n",
      "  0.0000000e+00 1.7753960e-24 0.0000000e+00 3.8803476e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 8.3308614e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7256116e-23 0.0000000e+00\n",
      "  0.0000000e+00 2.6782303e-24 0.0000000e+00 3.1801100e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.2366320e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5505904e-23 0.0000000e+00\n",
      "  0.0000000e+00 2.2351601e-24 0.0000000e+00 9.0820539e-27]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1071851e-32\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.9935080e-23 0.0000000e+00\n",
      "  0.0000000e+00 3.7461458e-24 0.0000000e+00 2.4750383e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.5816112e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.3723455e-23 0.0000000e+00\n",
      "  0.0000000e+00 4.4356781e-24 0.0000000e+00 2.9727379e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.8586385e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 8.5701123e-23 0.0000000e+00\n",
      "  0.0000000e+00 8.7838573e-24 0.0000000e+00 3.3698514e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.5664770e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3172197e-23 0.0000000e+00\n",
      "  0.0000000e+00 9.0408643e-24 0.0000000e+00 3.3045467e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.1647049e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5243874e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.0801197e-23 0.0000000e+00 5.8774784e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.7323463e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9181538e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.2409406e-23 0.0000000e+00 8.5679748e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3813750e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2377824e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.1475380e-23 0.0000000e+00 6.7779551e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4366728e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6838705e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.8114012e-23 0.0000000e+00 7.7857699e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.7683998e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 6.0544171e-24 0.0000000e+00\n",
      "  0.0000000e+00 7.2602995e-24 0.0000000e+00 7.5306406e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.2443997e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.9451106e-24 0.0000000e+00\n",
      "  0.0000000e+00 5.5414102e-24 0.0000000e+00 5.8428505e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6215907e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.3629549e-24 0.0000000e+00\n",
      "  0.0000000e+00 5.5817624e-24 0.0000000e+00 7.9100377e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.9863994e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 9.0474544e-24 0.0000000e+00\n",
      "  0.0000000e+00 3.5777761e-24 0.0000000e+00 7.0151262e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0433331e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.9922415e-24 0.0000000e+00\n",
      "  0.0000000e+00 2.3704917e-24 0.0000000e+00 3.5262566e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.0000376e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.6802953e-24 0.0000000e+00\n",
      "  0.0000000e+00 1.5587572e-24 0.0000000e+00 2.7693853e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.0042163e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 9.2740287e-24 0.0000000e+00\n",
      "  0.0000000e+00 1.0031250e-23 0.0000000e+00 3.2341118e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0432547e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2306919e-23 0.0000000e+00\n",
      "  0.0000000e+00 7.3494416e-24 0.0000000e+00 1.5723069e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.29858927e-33 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.54080943e-23 0.00000000e+00 0.00000000e+00 1.04472565e-23\n",
      "  0.00000000e+00 2.42266284e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7151998e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4603515e-23 0.0000000e+00\n",
      "  0.0000000e+00 7.9300463e-24 0.0000000e+00 3.3126767e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6967446e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6279409e-23 0.0000000e+00\n",
      "  0.0000000e+00 8.3538129e-24 0.0000000e+00 6.7085313e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.5026216e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7031606e-23 0.0000000e+00\n",
      "  0.0000000e+00 6.2846560e-24 0.0000000e+00 6.0190200e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0321017e-33\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3161256e-23 0.0000000e+00\n",
      "  0.0000000e+00 3.3319800e-24 0.0000000e+00 7.0957920e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.4409036e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 8.7276778e-24 0.0000000e+00\n",
      "  0.0000000e+00 3.2326086e-24 0.0000000e+00 4.4369787e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.4596877e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 6.6634931e-24 0.0000000e+00\n",
      "  0.0000000e+00 3.3292991e-24 0.0000000e+00 4.3317831e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2835984e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.7282399e-24 0.0000000e+00\n",
      "  0.0000000e+00 3.9033185e-24 0.0000000e+00 2.5219112e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6888835e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.3839671e-24 0.0000000e+00\n",
      "  0.0000000e+00 1.3605743e-23 0.0000000e+00 1.7631720e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.0159131e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2166912e-24 0.0000000e+00\n",
      "  0.0000000e+00 8.5630828e-24 0.0000000e+00 7.7612764e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.23079769e-34 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.01641229e-24 0.00000000e+00 0.00000000e+00 1.02339004e-23\n",
      "  0.00000000e+00 6.72113066e-26]]\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 769us/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8038543e-34\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.8431990e-24 0.0000000e+00\n",
      "  0.0000000e+00 8.5135092e-24 0.0000000e+00 2.9476016e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.1935626e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9345544e-24 0.0000000e+00\n",
      "  0.0000000e+00 2.8085929e-24 0.0000000e+00 1.0994527e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.8081565e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1209188e-24 0.0000000e+00\n",
      "  0.0000000e+00 1.9303673e-24 0.0000000e+00 4.7801770e-27]]\n",
      "1\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.8518320e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.8702761e-24 0.0000000e+00\n",
      "  0.0000000e+00 2.8272430e-24 0.0000000e+00 4.0044987e-27]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 8.1126392e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0862854e-24 0.0000000e+00\n",
      "  0.0000000e+00 4.5144242e-24 0.0000000e+00 3.2363920e-27]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.3143913e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0908812e-24 0.0000000e+00\n",
      "  0.0000000e+00 3.9482902e-24 0.0000000e+00 4.8389048e-27]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1097332e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2412261e-25 0.0000000e+00\n",
      "  0.0000000e+00 2.3365466e-24 0.0000000e+00 1.0684837e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3481561e-35\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.4934022e-25 0.0000000e+00\n",
      "  0.0000000e+00 3.8083775e-24 0.0000000e+00 1.4224068e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.9215110e-36\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0598354e-25 0.0000000e+00\n",
      "  0.0000000e+00 2.1058029e-24 0.0000000e+00 2.6194019e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 8.1973433e-36\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 4.1598963e-25 0.0000000e+00\n",
      "  0.0000000e+00 2.6644426e-24 0.0000000e+00 8.4858754e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.01664836e-35 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.56176864e-25 0.00000000e+00 0.00000000e+00 6.55653222e-24\n",
      "  0.00000000e+00 1.83122103e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.0126917e-36\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.9907566e-25 0.0000000e+00\n",
      "  0.0000000e+00 1.3340548e-23 0.0000000e+00 1.8230593e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 3.0938912e-36\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 3.5796583e-25 0.0000000e+00\n",
      "  0.0000000e+00 1.4352012e-23 0.0000000e+00 3.0740033e-25]]\n",
      "1\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "[[0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 8.354012e-37\n",
      "  0.000000e+00 0.000000e+00 0.000000e+00 7.059582e-26 0.000000e+00\n",
      "  0.000000e+00 4.191533e-24 0.000000e+00 4.362892e-26]]\n",
      "1\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6985901e-37\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3877829e-26 0.0000000e+00\n",
      "  0.0000000e+00 2.6900157e-24 0.0000000e+00 1.1711652e-26]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load your trained model\n",
    "model_path = 'AHAR_new13videos_savedmodel_epoch10_accuracy.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Define class mapping based on danger levels\n",
    "class_mapping = {\n",
    "    'Abuse': 2,          # Medium danger\n",
    "    'Arrest': 1,         # High danger\n",
    "    'Arson': 3,          # High danger\n",
    "    'Assault': 2,        # Medium danger\n",
    "    'Burglary': 3,       # High danger\n",
    "    'Explosion': 3,      # High danger\n",
    "    'Fighting': 2,       # Medium danger\n",
    "    'NormalVideos': 0,   # Normal\n",
    "    'RoadAccidents': 1,  # Low danger\n",
    "    'Robbery': 3,        # High danger\n",
    "    'Shooting': 3,       # High danger\n",
    "    'Shoplifting': 1,    # Low danger\n",
    "    'Stealing': 2,       # Medium danger\n",
    "    'Vandalism': 2       # Medium danger\n",
    "}\n",
    "\n",
    "# Open a video capture object\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\Harshi\\Downloads\\mixkit-boxers-hitting-in-a-fight-40967-medium.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Make a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    # Preprocess the frame (resize, convert to grayscale, etc.)\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = img_to_array(frame)\n",
    "    frame = preprocess_input(frame)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(frame)\n",
    "    print(predictions)\n",
    "\n",
    "#     # Convert predictions to class labels using class_mapping\n",
    "#     predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "#     # Check if the predicted label index is in class_mapping\n",
    "#     if predicted_label_index in class_mapping:\n",
    "#         predicted_label = class_mapping[predicted_label_index]\n",
    "#     else:\n",
    "# #         print(f\"Unexpected predicted label index: {predicted_label_index}\")\n",
    "#         predicted_label = 0\n",
    "\n",
    "    predicted_label_index=np.argmax(predictions)\n",
    "    print(predicted_label_index)\n",
    "    \n",
    "    keys_list=list(class_mapping.keys())\n",
    "    \n",
    "    key_at_index = keys_list[predicted_label_index]\n",
    "    value_at_index = class_mapping[key_at_index]\n",
    "\n",
    "    # Display the prediction on the copy of the frame\n",
    "    cv2.putText(display_frame, f'Danger Level: {value_at_index}', (20, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Video Prediction', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef762b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
